{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agonist11/colabadmixtools/blob/main/Test_ColabADMIXTOOLS_V4_8a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04iVpOTvZI7"
      },
      "source": [
        "# **ColabADMIXTOOLS Version 4.8a**\n",
        "This notebook is designed to make it easier for people to model themselves (or just the AADR) using ADMIXTOOLS (which includes qpAdm) with curated datasets. This notebook uses the AADR dataset from [here](https://reich.hms.harvard.edu/allen-ancient-dna-resource-aadr-downloadable-genotypes-present-day-and-ancient-dna-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Gkz5Uux8-l"
      },
      "source": [
        "You will need a Google account to be able to use Google Colaboratory. If you recieved this as a link, please make a copy for yourself using the **'File'** tab. If you received this a .ipynb, upload this notebook using the **'File'** tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Gy9JnoyqEE"
      },
      "source": [
        "Once the notebook is loaded, click **Connect** (top-right) to connect to a hosted runtime. CPU option should work fine. We will be borrowing storage and a CPU from Google. As a result, nothing will be saved once you disconnect from the session. However, you may use the Colab File Explorer (left sidebar under security key) to view, open, and download intermediate or final results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[1] Install Software**"
      ],
      "metadata": {
        "id": "BtePdSNjCQ1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import run, PIPE\n",
        "\n",
        "# @markdown **Select your preferences for the setup process**\n",
        "\n",
        "# @markdown Do you want to install ADMIXTOOLS?\n",
        "install_admixtools = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Do you want to install ADMIXTOOLS2? (This will increase setup time.)\n",
        "install_admixtools2 = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to check if a command exists\n",
        "def command_exists(command):\n",
        "    return run(['which', command], stdout=PIPE, stderr=PIPE).returncode == 0\n",
        "\n",
        "# Install R if not already installed\n",
        "if not command_exists('R'):\n",
        "    print(\"Installing R...\")\n",
        "    !sudo apt-get update -y\n",
        "    !sudo apt-get install -y r-base\n",
        "else:\n",
        "    print(\"R is already installed.\")\n",
        "\n",
        "# Install rpy2 if not already installed\n",
        "try:\n",
        "    import rpy2\n",
        "    print(\"rpy2 is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"Installing rpy2...\")\n",
        "    !pip install rpy2\n",
        "\n",
        "# Load the rpy2 extension for Python\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "# Check for PLINK\n",
        "if not os.path.exists('/content/plink'):\n",
        "    print(\"Installing PLINK (latest stable version)...\")\n",
        "    !wget https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20241022.zip -O plink.zip\n",
        "    !unzip -o plink.zip -d /content/\n",
        "    os.remove(\"plink.zip\")\n",
        "    print(\"PLINK installation complete!\")\n",
        "else:\n",
        "    print(\"PLINK is already installed.\")\n",
        "\n",
        "# Check and install ADMIXTOOLS\n",
        "if install_admixtools:\n",
        "    if not os.path.exists('/content/AdmixTools'):\n",
        "        print(\"Installing ADMIXTOOLS...\")\n",
        "        !apt-get update\n",
        "        !apt-get install -y build-essential libgsl-dev libopenblas-dev gfortran liblapacke-dev \\\n",
        "                           libssl-dev libffi-dev libncurses5-dev zlib1g zlib1g-dev \\\n",
        "                           libreadline-dev libbz2-dev libsqlite3-dev\n",
        "        !rm -rf AdmixTools\n",
        "        !git clone https://github.com/DReichLab/AdmixTools.git\n",
        "        %cd AdmixTools/src\n",
        "        !sed -i \"s/-Wimplicit/-Wimplicit -fcommon/\" Makefile\n",
        "        !make clobber\n",
        "        !make all LDLIBS=\"-llapacke -llapack -lgsl -lopenblas -lm -lnick\"\n",
        "        !make install\n",
        "        %cd /content/\n",
        "        print(\"ADMIXTOOLS installation complete!\")\n",
        "    else:\n",
        "        print(\"ADMIXTOOLS is already installed.\")\n",
        "\n",
        "# Check and install ADMIXTOOLS2\n",
        "if install_admixtools2:\n",
        "    try:\n",
        "        import rpy2.robjects as ro\n",
        "        print(\"Checking for ADMIXTOOLS2 installation...\")\n",
        "        ro.r('''\n",
        "        if (!requireNamespace(\"admixtools\", quietly = TRUE)) {\n",
        "            stop(\"ADMIXTOOLS2 is not installed.\")\n",
        "        }\n",
        "        ''')\n",
        "        print(\"ADMIXTOOLS2 is already installed.\")\n",
        "    except Exception as e:\n",
        "        print(\"Installing ADMIXTOOLS2...\")\n",
        "        ro.r('''\n",
        "        lib_path <- \"/usr/local/lib/R/site-library\"\n",
        "        install.packages(\"remotes\", lib = lib_path)\n",
        "        remotes::install_github(\"uqrmaie1/admixtools\", dependencies = TRUE, lib = lib_path)\n",
        "        ''')\n",
        "        print(\"ADMIXTOOLS2 installation complete!\")\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTN1OE0F_Kqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Both PLINK and rpy2 will be installed in any scenario. ADMIXTOOLS (AT1) installation is faster but model computation is slower. AT2 installation is slower but model computation is faster. We recommend exploration and rotation strategy with AT2 and double-checking with AT1 afterwards.**"
      ],
      "metadata": {
        "id": "-WeSp0z3LVWq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irfC9KGv0dWw"
      },
      "source": [
        "# **[2] Your DNA File Upload**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you only want to model samples within the AADR you may skip this section and move to [3] Dataset Selection.**"
      ],
      "metadata": {
        "id": "79PipZkXM0YG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1OTzXLCGh32l"
      },
      "outputs": [],
      "source": [
        "# @title Option 1: Upload 23andMe Raw Data (If you have AncestryDNA Raw Data, skip to Option 2)\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the user will upload only one genome file, you can check if a file has been uploaded successfully.\n",
        "if uploaded:\n",
        "    filename = next(iter(uploaded))\n",
        "    print(f\"File '{filename}' uploaded successfully.\")\n",
        "else:\n",
        "    print(\"No file uploaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23andMe formatted data works best for conversion. Please explore [DNA Kit Studio](https://www.dnagenics.com/dna-kit-studio/) on how to make this conversion possible. Some users have also found success with [this](https://tendna.com/en/dna-converter) converter as well.**"
      ],
      "metadata": {
        "id": "oSmLy92EKmAT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pLI8qaGnwnWW"
      },
      "outputs": [],
      "source": [
        "# @title Option 2: Upload and Convert AncestryDNA to 23andMe Raw Data Format\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def convert_ancestry_to_23andme(ancestry_content):\n",
        "    # Split content into lines and filter out the header and comments\n",
        "    lines = ancestry_content.strip().split(\"\\n\")\n",
        "    # Find the header end index and skip the header\n",
        "    header_end_idx = next(i for i, line in enumerate(lines) if line.startswith(\"rsid\"))\n",
        "    data_lines = lines[header_end_idx+1:]  # Skip header row\n",
        "\n",
        "    # Convert AncestryDNA format to 23andMe format with commented header\n",
        "    converted_lines = [\"# rsid\\tchromosome\\tposition\\tgenotype\"]\n",
        "    for line in data_lines:\n",
        "        parts = line.split(\"\\t\")\n",
        "        if len(parts) == 5:  # Ensure line has 5 columns\n",
        "            rsid, chromosome, position, allele1, allele2 = parts\n",
        "            genotype = allele1 + allele2\n",
        "            converted_lines.append(f\"{rsid}\\t{chromosome}\\t{position}\\t{genotype}\")\n",
        "\n",
        "    return \"\\n\".join(converted_lines)\n",
        "\n",
        "# @markdown Choose if you want to upload a new file or use an existing file:\n",
        "file_option = \"Use Existing File\"  # @param [\"Upload New File\", \"Use Existing File\"]\n",
        "# @markdown If using an existing file, please provide the file path:\n",
        "existing_file_path = \"/content/AncestryDNArawrtest4.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "if file_option == \"Upload New File\":\n",
        "    uploaded = files.upload()\n",
        "    # Check if a file has been uploaded successfully.\n",
        "    if uploaded:\n",
        "        filename = next(iter(uploaded))\n",
        "        content = uploaded[filename].decode(\"utf-8\")\n",
        "\n",
        "        # Check if the uploaded file is in AncestryDNA format\n",
        "        if \"AncestryDNA raw data download\" in content:\n",
        "            print(f\"Converting '{filename}' from AncestryDNA to 23andMe format...\")\n",
        "            converted_content = convert_ancestry_to_23andme(content)\n",
        "            converted_filename = filename.replace(\".txt\", \"_converted.txt\")\n",
        "\n",
        "            # Saving the converted file into the current folder\n",
        "            with open(converted_filename, \"w\") as f:\n",
        "                f.write(converted_content)\n",
        "            print(f\"File converted and saved as '{converted_filename}' in the current folder.\")\n",
        "        else:\n",
        "            print(f\"File '{filename}' does not appear to be in AncestryDNA format.\")\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "\n",
        "elif file_option == \"Use Existing File\":\n",
        "    if os.path.exists(existing_file_path):\n",
        "        with open(existing_file_path, \"r\") as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Check if the file is in AncestryDNA format\n",
        "        if \"AncestryDNA raw data download\" in content:\n",
        "            print(f\"Converting '{existing_file_path}' from AncestryDNA to 23andMe format...\")\n",
        "            converted_content = convert_ancestry_to_23andme(content)\n",
        "            converted_filename = existing_file_path.replace(\".txt\", \"_converted.txt\")\n",
        "\n",
        "            # Saving the converted file into the current folder\n",
        "            with open(converted_filename, \"w\") as f:\n",
        "                f.write(converted_content)\n",
        "            print(f\"File converted and saved as '{converted_filename}' in the current folder.\")\n",
        "        else:\n",
        "            print(f\"File '{existing_file_path}' does not appear to be in AncestryDNA format.\")\n",
        "    else:\n",
        "        print(f\"File '{existing_file_path}' does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mfi4KH8GH22n"
      },
      "outputs": [],
      "source": [
        "# @title Option 3: Mount Google Drive and Unzip Folder Previous Files (Returning Users)\n",
        "# @markdown Enter the path to your zip folder and run this cell to mount your Google Drive. If you previously ran Step 7 of this notebook, the zipped folder path will usually look like \"/content/drive/MyDrive/colabadmixtools/examplefolder.zip\"\n",
        "zip_folder_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Full path to the zip file\n",
        "zip_file_path = os.path.join('/content/drive/MyDrive/', zip_folder_path)\n",
        "\n",
        "# Check if the zip file exists\n",
        "if os.path.exists(zip_file_path) and zip_file_path.endswith('.zip'):\n",
        "    # Unzipping the contents to /content folder\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/')\n",
        "        print(f\"Contents of '{zip_folder_path}' have been extracted to '/content/'\")\n",
        "else:\n",
        "    print(f\"Zip file not found at '{zip_folder_path}'. Please ensure the path is correct and includes the zip folder name.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optional Step: Mount Google Drive and Upload SNP Lists\n",
        "# @markdown Enter the path to the folder containing your SNP lists and run this cell to mount your Google Drive.\n",
        "# @markdown The folder path will usually look like \"/content/drive/MyDrive/yourfolder/\"\n",
        "snp_list_folder_path = \"/content/drive/MyDrive/colabadmixtools/snplists\" #@param {type:\"string\"}\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(snp_list_folder_path) and os.path.isdir(snp_list_folder_path):\n",
        "    # Destination folder in Colab\n",
        "    destination_folder = '/content/snplist_files'\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "    # Copying the contents to the destination folder\n",
        "    for item in os.listdir(snp_list_folder_path):\n",
        "        source = os.path.join(snp_list_folder_path, item)\n",
        "        destination = os.path.join(destination_folder, item)\n",
        "        if os.path.isfile(source):\n",
        "            shutil.copy2(source, destination)\n",
        "        elif os.path.isdir(source):\n",
        "            shutil.copytree(source, destination, dirs_exist_ok=True)\n",
        "\n",
        "    print(f\"Contents of '{snp_list_folder_path}' have been copied to '{destination_folder}'\")\n",
        "else:\n",
        "    print(f\"Folder not found at '{snp_list_folder_path}'. Please ensure the path is correct and includes the folder name.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y2hCnTabSp1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you do not have the snplists, modeling your sample can lead to high Standard Errors. Please ask whoever sent you this notebook to provide you the snplists. Then use the Optional Step above if it is in your Google Drive or manually upload them to this session using the Upload function on the left.**"
      ],
      "metadata": {
        "id": "AkPECXj-JpyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### [Experimental] DNA File Conversion to 23andMe Format\n",
        "#@markdown **Specify your DNA file path and configure the settings below.**\n",
        "\n",
        "import os\n",
        "\n",
        "# Set up terraseq\n",
        "def setup_terraseq():\n",
        "    terraseq_url = \"https://github.com/enelsr/terraseq/releases/latest/download/terraseq\"\n",
        "    os.system(f\"wget -O terraseq {terraseq_url}\")\n",
        "    os.system(\"chmod +x terraseq\")\n",
        "    print(\"terraseq setup completed successfully.\")\n",
        "\n",
        "#@markdown **Specify the file path of your DNA file:**\n",
        "input_file = \"/content/MyHeritage_raw_dna_data.csv\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Select the input file format:**\n",
        "input_format = \"myheritage\"  #@param [\"23andme\", \"ancestry\", \"myheritage\", \"ftdnav1\", \"ftdnav2\"]\n",
        "\n",
        "#@markdown **Specify the output file name:**\n",
        "output_file = \"converted_23andme.txt\"  #@param {type:\"string\"}\n",
        "\n",
        "# Convert the DNA file\n",
        "def convert_dna_file():\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"Error: The file path '{input_file}' does not exist. Please check the file path and re-run the cell.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Converting {input_file} from {input_format} to 23andMe format...\")\n",
        "    try:\n",
        "        command = f\"./terraseq convert --inFile {input_file} --inFormat {input_format} --outFormat 23andme --outFile {output_file}\"\n",
        "        os.system(command)\n",
        "\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"Conversion successful! Output file: {output_file}\")\n",
        "        else:\n",
        "            print(\"Conversion failed. Please check your input file and format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during conversion: {e}\")\n",
        "\n",
        "# Ensure terraseq is set up\n",
        "setup_terraseq()\n",
        "\n",
        "# Perform the conversion\n",
        "convert_dna_file()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "labp1M-EpuTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIHcUfjY1DV7"
      },
      "source": [
        "# **[3] Dataset Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The 1240K has more coverage than the 1240K+HO. However, the 1240K+HO has more modern samples. You can download one after the other if you would like to explore both datasets.**"
      ],
      "metadata": {
        "id": "l9Am_c6ONKLn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e-9bhlIJvT1o"
      },
      "outputs": [],
      "source": [
        "# @title Download 1240K or HO Datasets (AADR v62)\n",
        "# @markdown Select the dataset you want to download:\n",
        "\n",
        "dataset_choice = \"1240K+HO\" #@param [\"1240K\", \"1240K+HO\"]\n",
        "\n",
        "# Define the URLs and corresponding filenames for each dataset\n",
        "dataset_files = {\n",
        "    \"1240K\": [\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537413\", \"aadr_v62.0_1240K_public.anno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537126\", \"aadr_v62.0_1240K_public.geno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537414\", \"aadr_v62.0_1240K_public.ind\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537415\", \"aadr_v62.0_1240K_public.snp\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537416\", \"v62.0_1240K_public.xlsx\")\n",
        "    ],\n",
        "    \"1240K+HO\": [\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537417\", \"aadr_v62.0_HO_public.anno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537419\", \"aadr_v62.0_HO_public.geno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537420\", \"aadr_v62.0_HO_public.ind\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537421\", \"aadr_v62.0_HO_public.snp\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537422\", \"v62.0_HO_public.xlsx\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "selected_files = dataset_files[dataset_choice]\n",
        "\n",
        "print(f\"Downloading {dataset_choice} dataset files...\")\n",
        "for url, filename in selected_files:\n",
        "    !wget --no-check-certificate {url} -O /content/{filename}\n",
        "\n",
        "print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Look for the associated xlsx spreadsheet on the left File Explorer to look at all the samples in the dataset. When modeling, we refer to the Group ID, which may contain one or more samples.**"
      ],
      "metadata": {
        "id": "CV2BriRHOM50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[4] Merging Yourself with the AADR**"
      ],
      "metadata": {
        "id": "9DQIkKnjPSIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **You can skip to Step 5 if you just want to model within the AADR. For now, only merging with the +HO dataset is possible because merging with the 1240K dataset requires more RAM with a standard Colab Runtime. If you (or someone else) has ColabPro, they can utilize the High-Ram runtime to get around this issue.**"
      ],
      "metadata": {
        "id": "6jKui3wT9vvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# @markdown ### Step 1: Specify Inputs\n",
        "\n",
        "# @markdown **Filepath to your 23andMe TXT File**:\n",
        "genome_filepath = \"/content/converted_23andme.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Output Base Prefix**: Define a name for intermediate and final files.\n",
        "output_base = \"Florio\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **.fam File Parameters**:\n",
        "# @markdown These fields will auto-fill based on `output_base`, but you can edit `sex_code` as needed.\n",
        "family_id = output_base  # Automatically set to output_base\n",
        "individual_id = output_base  # Automatically set to output_base\n",
        "father_id = '0'  # Always 0\n",
        "mother_id = '0'  # Always 0\n",
        "sex_code = '1'  # @param [\"1\", \"2\", \"0\"]  # Default is 1 (male)\n",
        "phenotype_value = '0'  # Always 0\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Trim Using SNP List?**\n",
        "trim_with_snplist = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **If Trimming**, specify:\n",
        "snplist_path = \"/content/HOsnplist.snplist\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Merge Dataset Parameters\n",
        "# @markdown Specify the file paths for the dataset you want to merge with:\n",
        "geno1_path = \"/content/aadr_v62.0_HO_public.geno\"  # @param {type:\"string\"}\n",
        "snp1_path = \"/content/aadr_v62.0_HO_public.snp\"  # @param {type:\"string\"}\n",
        "ind1_path = \"/content/aadr_v62.0_HO_public.ind\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Number of Threads for Mergeit**:\n",
        "num_threads = 2  # @param {type:\"integer\"}\n",
        "\n",
        "# Ensure required inputs are valid\n",
        "if not genome_filepath:\n",
        "    raise ValueError(\"Please specify the filepath to your 23andMe TXT file.\")\n",
        "if not output_base:\n",
        "    raise ValueError(\"Please specify an output base name.\")\n",
        "if not geno1_path or not snp1_path or not ind1_path:\n",
        "    raise ValueError(\"Please specify the file paths for the dataset to merge with.\")\n",
        "\n",
        "# Define paths dynamically based on user inputs\n",
        "fam_file_path = f\"/content/{output_base}.fam\"\n",
        "plink_file_prefix = f\"/content/{output_base}\"\n",
        "if trim_with_snplist:\n",
        "    output_base_trimmed = f\"{output_base}trimmed\"\n",
        "    plink_file_prefix = f\"/content/{output_base_trimmed}\"\n",
        "\n",
        "# Paths for EIGENSTRAT conversion\n",
        "bedfilepath = f\"/content/{output_base_trimmed}.bed\" if trim_with_snplist else f\"/content/{output_base}.bed\"\n",
        "bimfilepath = f\"/content/{output_base_trimmed}.bim\" if trim_with_snplist else f\"/content/{output_base}.bim\"\n",
        "famfilepath = f\"/content/{output_base_trimmed}.fam\" if trim_with_snplist else f\"/content/{output_base}.fam\"\n",
        "genotypeoutname = f\"{output_base}_converted.geno\"\n",
        "snpoutname = f\"{output_base}_converted.snp\"\n",
        "indivoutname = f\"{output_base}_converted.ind\"\n",
        "\n",
        "# Paths for merging datasets\n",
        "geno2_path = genotypeoutname\n",
        "snp2_path = snpoutname\n",
        "ind2_path = indivoutname\n",
        "output_geno_path = f\"{output_base}_merged.geno\"\n",
        "output_snp_path = f\"{output_base}_merged.snp\"\n",
        "output_ind_path = f\"{output_base}_merged.ind\"\n",
        "\n",
        "# Step 2: Add Swap Memory to Prevent Out-of-Memory Issues\n",
        "print(\"Creating swap memory...\")\n",
        "swap_file_path = \"/swapfile\"\n",
        "os.system(f\"fallocate -l 8G {swap_file_path}\")\n",
        "os.system(f\"chmod 600 {swap_file_path}\")\n",
        "os.system(f\"mkswap {swap_file_path}\")\n",
        "os.system(f\"swapon {swap_file_path}\")\n",
        "print(\"Swap memory created successfully.\")\n",
        "\n",
        "# Step 3: Add AdmixTools to PATH\n",
        "print(\"Adding AdmixTools to PATH...\")\n",
        "os.environ['PATH'] += os.pathsep + \"/content/AdmixTools/bin\"\n",
        "!which qpfstats\n",
        "\n",
        "# Step 4: Convert Genome File with PLINK\n",
        "print(\"Running PLINK conversion...\")\n",
        "!{os.path.join('/content', 'plink')} --23file {genome_filepath} --list-23-indels --allow-no-sex --make-bed --out {output_base}\n",
        "\n",
        "# Step 5: Update the .fam File\n",
        "print(\"Updating .fam file...\")\n",
        "new_fam_line = f\"{family_id} {individual_id} {father_id} {mother_id} {sex_code} {phenotype_value}\\n\"\n",
        "with open(fam_file_path, 'w') as fam_file:\n",
        "    fam_file.write(new_fam_line)\n",
        "print(f\".fam file updated successfully: {fam_file_path}\")\n",
        "\n",
        "# Step 6: Trim PLINK File Using SNP List (if selected)\n",
        "if trim_with_snplist:\n",
        "    if not os.path.isfile(snplist_path):\n",
        "        raise ValueError(f\"Selected SNP list file '{snplist_path}' does not exist.\")\n",
        "    print(\"Trimming PLINK file...\")\n",
        "    trim_command = f\"/content/plink --bfile {output_base} --extract {snplist_path} --make-bed --allow-no-sex --out {output_base_trimmed}\"\n",
        "    subprocess.run(trim_command, shell=True, check=True)\n",
        "    print(f\"Trimmed PLINK file created: {output_base_trimmed}\")\n",
        "\n",
        "# Step 7: Create Parameter File for EIGENSTRAT Conversion\n",
        "print(\"Creating convertf parameter file...\")\n",
        "convertf_param_content = f\"\"\"\n",
        "genotypename: {bedfilepath}\n",
        "snpname: {bimfilepath}\n",
        "indivname: {famfilepath}\n",
        "genotypeoutname: {genotypeoutname}\n",
        "snpoutname: {snpoutname}\n",
        "indivoutname: {indivoutname}\n",
        "prodercheck: YES\n",
        "\"\"\"\n",
        "with open(\"/content/convertf_param.par\", \"w\") as param_file:\n",
        "    param_file.write(convertf_param_content)\n",
        "print(\"convertf parameter file created successfully.\")\n",
        "\n",
        "# Step 8: Convert PLINK to PACKEDANCESTRYMAP\n",
        "print(\"Running convertf...\")\n",
        "!convertf -p /content/convertf_param.par\n",
        "\n",
        "# Step 9: Create Parameter File for Dataset Merging\n",
        "print(\"Creating mergeit parameter file...\")\n",
        "mergeit_param_content = f\"\"\"\n",
        "geno1: {geno1_path}\n",
        "snp1: {snp1_path}\n",
        "ind1: {ind1_path}\n",
        "geno2: {geno2_path}\n",
        "snp2: {snp2_path}\n",
        "ind2: {ind2_path}\n",
        "genooutfilename: {output_geno_path}\n",
        "snpoutfilename: {output_snp_path}\n",
        "indoutfilename: {output_ind_path}\n",
        "testmismatch: NO\n",
        "numthreads: {num_threads}\n",
        "\"\"\"\n",
        "with open(\"/content/mergeit_param.par\", \"w\") as merge_param_file:\n",
        "    merge_param_file.write(mergeit_param_content)\n",
        "print(\"mergeit parameter file created successfully.\")\n",
        "\n",
        "# Step 10: Run mergeit\n",
        "print(\"Merging datasets...\")\n",
        "!mergeit -p /content/mergeit_param.par\n",
        "\n",
        "# Step 11: Verify Merging Results\n",
        "print(\"Verifying merged files...\")\n",
        "merged_files_exist = all(os.path.exists(file) for file in [output_geno_path, output_snp_path, output_ind_path])\n",
        "if merged_files_exist:\n",
        "    print(\"Merging completed successfully.\")\n",
        "else:\n",
        "    print(\"An error occurred during merging.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4cDNUPDEU0O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGzig6132SSB"
      },
      "source": [
        "**While the previous step is running, I urge you to use the File Explorer and double-click on the AADR .ind file. The 1st column is the family+individual ID. The 2nd column is the sex (M, F, unspecified). The 3rd column is the sample label: Scroll through the labels and start to form a list of right populations and left populations (samples you think you are admixed with). The number of left/source populations must be less than or equal to the number of right/reference.Read through [this](https://pmc.ncbi.nlm.nih.gov/articles/PMC8049561/) paper to obtain insight into the theory.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZG9UI3J36rd"
      },
      "source": [
        "# **[5] AT2 qpAdm Prep and Running**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIYz130a4C1I"
      },
      "source": [
        "**You should now have a dataset with your data merged in. Use the File Explorer and double-click the .ind file. It should open on the right and your sample will be ALL the way at the bottom with ??? in the 3rd label. Manually rename yourself with your desired label and remove spaces such that there is only one space between your sex and label.**\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input parameters using markdown or comment annotations.\n",
        "# Replace this with the appropriate input method if using a specific notebook interface.\n",
        "\n",
        "# Dataset prefix\n",
        "prefix = \"/content/Florio_merged\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations (can be comma-separated string or quoted list)\n",
        "left_poplist = \"Tunisia_Kerkouane_Punic_oAfrica1.SG,Gambian.DG\"  # @param {type:\"string\"}\n",
        "right_poplist = \"Mbuti.DG,Luxembourg_Mesolithic.AG,Turkey_Southeast_Cayonu_PPN.SG,Hungary_Langobard_o2.AG,Iran_GanjDareh_Historic.AG,Greece_Logkas_MBA.SG,USA_CA_SantaRosa_7400BP.AG\"  # @param {type:\"string\"}\n",
        "target = 'Florio'  # @param {type:\"string\"}\n",
        "\n",
        "# File names for outputs\n",
        "weights_file = \"weights1.csv\"  # @param {type:\"string\"}\n",
        "popdrop_file = \"popdrop1.csv\"  # @param {type:\"string\"}\n",
        "\n",
        "# Detach shinyjs option\n",
        "detach_shinyjs = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# allsnps option\n",
        "allsnps = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse population lists\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        # Split by commas and strip whitespace/quotes\n",
        "        return [pop.strip().strip(\"'\") for pop in poplist.split(',')]\n",
        "    return poplist\n",
        "\n",
        "# Parse the population lists\n",
        "left = parse_poplist(left_poplist)\n",
        "right = parse_poplist(right_poplist)\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['left'] = robjects.StrVector(left)\n",
        "robjects.globalenv['right'] = robjects.StrVector(right)\n",
        "robjects.globalenv['target'] = target\n",
        "robjects.globalenv['weights_file'] = weights_file\n",
        "robjects.globalenv['popdrop_file'] = popdrop_file\n",
        "robjects.globalenv['detach_shinyjs'] = detach_shinyjs\n",
        "robjects.globalenv['allsnps'] = allsnps\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D1KBgV5EdcXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Run qpAdm (AT2)**\n",
        "\n",
        "%%R\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "\n",
        "# Retrieve the parameters passed from Python\n",
        "prefix <- get(\"prefix\", envir = .GlobalEnv)\n",
        "left <- get(\"left\", envir = .GlobalEnv)\n",
        "right <- get(\"right\", envir = .GlobalEnv)\n",
        "target <- get(\"target\", envir = .GlobalEnv)\n",
        "weights_file <- get(\"weights_file\", envir = .GlobalEnv)\n",
        "popdrop_file <- get(\"popdrop_file\", envir = .GlobalEnv)\n",
        "detach_shinyjs <- get(\"detach_shinyjs\", envir = .GlobalEnv)\n",
        "allsnps <- get(\"allsnps\", envir = .GlobalEnv)\n",
        "\n",
        "# Detach shinyjs if specified\n",
        "if (detach_shinyjs) {\n",
        "  try(detach(\"package:shinyjs\", unload=TRUE), silent=TRUE)\n",
        "}\n",
        "\n",
        "# Print the parameters to verify they are set correctly\n",
        "print(paste(\"Prefix path: \", prefix))\n",
        "print(paste(\"Left populations: \", toString(left)))\n",
        "print(paste(\"Right populations: \", toString(right)))\n",
        "print(paste(\"Target population: \", target))\n",
        "print(paste(\"Weights file: \", weights_file))\n",
        "print(paste(\"Popdrop file: \", popdrop_file))\n",
        "print(paste(\"Detach shinyjs: \", detach_shinyjs))\n",
        "print(paste(\"All SNPs: \", allsnps))\n",
        "\n",
        "# Execute qpAdm analysis\n",
        "results <- qpadm(prefix, left, right, target, allsnps = allsnps)\n",
        "\n",
        "# Set output options for detailed viewing in the console\n",
        "options(dplyr.width = Inf, max.print = 100000, digits = 10)\n",
        "\n",
        "# Output admixture results to CSV files\n",
        "write.csv(results$weights, weights_file, row.names = FALSE)\n",
        "write.csv(results$popdrop, popdrop_file, row.names = FALSE)\n",
        "\n",
        "# Print detailed results to the console\n",
        "print(results$weights, n = Inf)\n",
        "print(results$popdrop, n = Inf)\n",
        "if (\"f4\" %in% names(results)) {\n",
        "  print(results$f4, n = Inf)\n",
        "}\n",
        "\n",
        "# Indicate completion\n",
        "print(\"qpAdm analysis complete. Results are also saved in CSV files.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "l0KnHxSvdrlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[6] AT1 qpAdm Prep and Running**"
      ],
      "metadata": {
        "id": "sneaiW05ffme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gq3ifm7T_xxA"
      },
      "outputs": [],
      "source": [
        "#@title Prepare qpAdm Analysis Files and Create Population Lists\n",
        "%cd /content/\n",
        "%pwd\n",
        "#@markdown Enter the name/label of the target population (first in the left file):\n",
        "target_population = \"Florio\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the names/labels of the source populations (separate by commas):\n",
        "source_populations = \"Tunisia_Kerkouane_Punic_oAfrica1.SG,Gambian.DG\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the names/labels of the reference populations (right file, separate by commas):\n",
        "reference_populations = \"Mbuti.DG,Luxembourg_Mesolithic.AG,Turkey_Southeast_Cayonu_PPN.SG,Hungary_Langobard_o2.AG,Iran_GanjDareh_Historic.AG,Greece_Logkas_MBA.SG,USA_CA_SantaRosa_7400BP.AG\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the prefix for your merged dataset files (e.g., `S1` if you have `S1.ind`, `S1.snp`, `S1.geno`):\n",
        "dataset_prefix = \"Florio_merged\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Select YES or NO for allsnps:\n",
        "allsnps = \"YES\" #@param [\"YES\", \"NO\"]\n",
        "\n",
        "#@markdown Select YES or NO for inbreed:\n",
        "inbreed = \"NO\" #@param [\"YES\", \"NO\"]\n",
        "\n",
        "# Prepare populations lists\n",
        "source_list = source_populations.split(\",\")\n",
        "reference_list = reference_populations.split(\",\")\n",
        "\n",
        "# Save left1 file\n",
        "left1_content = f\"{target_population}\\n\" + \"\\n\".join(source_list)\n",
        "with open(\"left1.txt\", \"w\") as file:\n",
        "    file.write(left1_content)\n",
        "\n",
        "# Save right1 file\n",
        "right1_content = \"\\n\".join(reference_list)\n",
        "with open(\"right1.txt\", \"w\") as file:\n",
        "    file.write(right1_content)\n",
        "\n",
        "# Save poplist file (arranged as reference pops on top, then target, then sources)\n",
        "poplist_content = \"\\n\".join(reference_list) + f\"\\n{target_population}\\n\" + \"\\n\".join(source_list)\n",
        "with open(\"poplist\", \"w\") as file:\n",
        "    file.write(poplist_content)\n",
        "\n",
        "print(\"Left, right, and poplist population files have been saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HlwxMUuSDIk1"
      },
      "outputs": [],
      "source": [
        "#@title Create the parqpAdm File\n",
        "\n",
        "parqpAdm_content = f\"\"\"\n",
        "S1:                  {dataset_prefix}\n",
        "indivname:       {dataset_prefix}.ind\n",
        "snpname:         {dataset_prefix}.snp\n",
        "genotypename:    {dataset_prefix}.geno\n",
        "popleft:  left1.txt\n",
        "popright: right1.txt\n",
        "details:  YES\n",
        "allsnps:  {allsnps}\n",
        "inbreed:  {inbreed}\n",
        "summary:  YES\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/parqpAdm.txt\", \"w\") as file:\n",
        "    file.write(parqpAdm_content)\n",
        "\n",
        "print(\"Parameter file for qpAdm has been created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN5TKcI-DOZw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Add AdmixTools to the Environment Path and Verify\n",
        "import os\n",
        "\n",
        "# Add AdmixTools bin directory to PATH\n",
        "os.environ['PATH'] += os.pathsep + \"/content/AdmixTools/bin\"\n",
        "\n",
        "# Confirm qpfstats is now accessible\n",
        "!which qpfstats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing F-statistics allows users to calculate genetic differentation and relatedness for an entire poplist.**\n",
        "\n",
        "## **The poplist is composed of the Target + Source + Reference populations combined**\n",
        "\n",
        "**If you wish to try different combinatorials (e.g. swapping the Target, moving a Source to Reference or vice-versa, removing a pop, etc), please add it to Reference pop list to save yourself some time. You can always swap and remove pops from the poplist, but never add without computing f-statistics all over again.**\n",
        "\n",
        "**To run different combinations, simply do all of Step 6 (this section) without Computing F-Statistics (the cell below), as you have already done so for the given poplist.**"
      ],
      "metadata": {
        "id": "uJqFuBimePGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cKV60ueoK9xl"
      },
      "outputs": [],
      "source": [
        "#@title Compute F-Statistics\n",
        "\n",
        "parqpfstats_content = f\"\"\"\n",
        "DIR: /content/\n",
        "S1: {dataset_prefix}\n",
        "indivname: /content/{dataset_prefix}.ind\n",
        "snpname: /content/{dataset_prefix}.snp\n",
        "genotypename: /content/{dataset_prefix}.geno\n",
        "poplistname: poplist\n",
        "fstatsoutname: fstatsa.txt\n",
        "allsnps: YES\n",
        "inbreed: NO\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/parqpfstats.txt\", \"w\") as file:\n",
        "    file.write(parqpfstats_content)\n",
        "\n",
        "!qpfstats -p /content/parqpfstats.txt\n",
        "print(\"F-statistics computation completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run qpAdm Analysis\n",
        "#@markdown Enter the desired output filename (without .txt extension):\n",
        "output_filename = \"results3\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the filepath to the fstats file (if any):\n",
        "fstats_filepath = \"/content/fstatsa.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Do you want to use the precomputed fstats file?\n",
        "use_fstats = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Modify parqpAdm.txt if fstats file is used\n",
        "if use_fstats and fstats_filepath:\n",
        "    with open(\"/content/parqpAdm.txt\", \"a\") as file:\n",
        "        file.write(f\"fstatsname: {fstats_filepath}\\n\")\n",
        "\n",
        "! /content/AdmixTools/bin/qpAdm -p /content/parqpAdm.txt > /content/{output_filename}.txt\n",
        "print(f\"qpAdm analysis completed successfully. Results saved to {output_filename}.txt\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jSg9CykpDiAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZx-bsMS53kz"
      },
      "source": [
        "**After running the previous code cell, your results should be in the File Explorer on the left. Double-click to open them or right-click to Download.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F07l5ivu6E4L"
      },
      "source": [
        "# **[6b] Data Analysis and Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_bh7zix6MUf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import textwrap\n",
        "import numpy as np\n",
        "\n",
        "# @title Parse and Visualize qpAdm Output\n",
        "# @markdown Please paste the path to your qpAdm result file:\n",
        "qpadm_results_path = \"/content/results3.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "def parse_qpadm_output(filepath):\n",
        "    try:\n",
        "        with open(filepath) as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract target population\n",
        "        target_population = content.split('left pops:\\n')[1].split('\\n')[0].strip().rsplit(maxsplit=1)[0]\n",
        "\n",
        "        # Extract left populations\n",
        "        left_pops_raw = content.split('left pops:\\n')[1].split('\\n\\n')[0].strip().split('\\n')[1:]  # Skip target population\n",
        "        left_pops = [pop.rsplit(maxsplit=1)[0] for pop in left_pops_raw]\n",
        "\n",
        "        # Extract right populations\n",
        "        right_pops_raw = content.split('right pops:\\n')[1].split('\\n\\n')[0].strip().split('\\n')\n",
        "        right_pops = [pop.rsplit(maxsplit=1)[0] for pop in right_pops_raw]\n",
        "\n",
        "        # Extract best coefficients and standard errors\n",
        "        best_coeffs_raw = content.split('best coefficients:')[1].split('\\n')[0].strip()\n",
        "        best_coeffs = [float(bc) * 100 for bc in best_coeffs_raw.split()]  # Convert to percentages\n",
        "\n",
        "        std_errors_raw = content.split('std. errors:')[1].split('\\n')[0].strip()\n",
        "        std_errors = [float(se) * 100 for se in std_errors_raw.split()]  # Convert to percentages\n",
        "\n",
        "        # Extract chi-squared value\n",
        "        chi_squared = float(content.split('chisq:')[1].split()[0])\n",
        "\n",
        "        # Extract p-value\n",
        "        p_value_line = content.split('tail:')[1].split()[0]\n",
        "        p_value = float(p_value_line.strip())\n",
        "\n",
        "        # Construct DataFrame\n",
        "        df = pd.DataFrame({\n",
        "            'Source Population': left_pops,\n",
        "            'Admixture Proportion': best_coeffs,\n",
        "            'Standard Error': std_errors,\n",
        "            'Chi-Squared': [chi_squared] * len(left_pops),\n",
        "            'P-Value': [p_value] * len(left_pops)\n",
        "        })\n",
        "\n",
        "        return df, target_population, right_pops\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing the qpAdm output: {e}\")\n",
        "        return pd.DataFrame(), '', []\n",
        "\n",
        "# Parse the results and check if the DataFrame is not empty\n",
        "df_admixture, target_population, right_pops = parse_qpadm_output(qpadm_results_path)\n",
        "if not df_admixture.empty:\n",
        "    print(df_admixture)\n",
        "    print(\"\\nReference Populations Used:\")\n",
        "    for pop in right_pops:\n",
        "        print(pop)\n",
        "else:\n",
        "    print(\"Parsed DataFrame is empty or an error was encountered.\")\n",
        "\n",
        "# @title Select Plot Type\n",
        "# @markdown Choose the type of plot to display:\n",
        "plot_type = \"Pie Chart\"  # @param [\"Bar Graph\", \"Pie Chart\"]\n",
        "\n",
        "def wrap_text(text, width=50):\n",
        "    wrapped_lines = textwrap.wrap(text, width)\n",
        "    return \"\\n\".join(wrapped_lines)\n",
        "\n",
        "def create_plot(plot_type):\n",
        "    if not df_admixture.empty:\n",
        "        sns.set(style=\"whitegrid\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
        "\n",
        "        if plot_type == \"Bar Graph\":\n",
        "            palette = sns.color_palette(\"deep\", len(df_admixture))\n",
        "            bars = ax.bar(df_admixture['Source Population'], df_admixture['Admixture Proportion'], color=palette)\n",
        "\n",
        "            for bar, prop, se in zip(bars, df_admixture['Admixture Proportion'], df_admixture['Standard Error']):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.2f}% ± {se:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
        "\n",
        "            ax.set_title(f'Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {df_admixture[\"Chi-Squared\"].iloc[0]:.2f}, P-Value: {df_admixture[\"P-Value\"].iloc[0]:.12g})', fontsize=9, fontweight='bold')\n",
        "            ax.set_xlabel('Source Population', fontsize=10, fontweight='bold')\n",
        "            ax.set_ylabel('Admixture Proportion (%)', fontsize=10, fontweight='bold')\n",
        "            ax.tick_params(axis='x', rotation=45, labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "            ax.tick_params(axis='y', labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "\n",
        "            for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "                label.set_fontweight('bold')\n",
        "\n",
        "            ax.spines['top'].set_linewidth(1.5)\n",
        "            ax.spines['right'].set_linewidth(1.5)\n",
        "            ax.spines['bottom'].set_linewidth(1.5)\n",
        "            ax.spines['left'].set_linewidth(1.5)\n",
        "\n",
        "            wrapped_text = wrap_text(f'Reference Populations: {\", \".join(right_pops)}', width=60)\n",
        "            plt.figtext(0.5, -0.05, wrapped_text, ha='center', va='top', fontsize=8)\n",
        "\n",
        "        elif plot_type == \"Pie Chart\":\n",
        "            if np.any(df_admixture['Admixture Proportion'] <= 0):\n",
        "                print(\"Admixture proportions must be positive for pie charts.\")\n",
        "                return\n",
        "\n",
        "            wedges, texts = ax.pie(\n",
        "                df_admixture['Admixture Proportion'],\n",
        "                colors=sns.color_palette(\"deep\", len(df_admixture)),\n",
        "                startangle=140,\n",
        "                wedgeprops=dict(edgecolor='black', width=0.3)\n",
        "            )\n",
        "\n",
        "            # Remove pie chart labels and percentages\n",
        "            for text in texts:\n",
        "                text.set_text('')\n",
        "\n",
        "            ax.legend(wedges, [f'{pop}: {prop:.2f}% ± {se:.2f}%' for pop, prop, se in zip(df_admixture['Source Population'], df_admixture['Admixture Proportion'], df_admixture['Standard Error'])], title=\"Admixture Proportions\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=10, title_fontsize='12')\n",
        "\n",
        "            plt.figtext(0.625, 0.97, f'Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {df_admixture[\"Chi-Squared\"].iloc[0]:.2f}, P-Value: {df_admixture[\"P-Value\"].iloc[0]:.12g})', ha='center', va='top', fontsize=10, fontweight='bold')\n",
        "            wrapped_text = wrap_text(f'Reference Populations: {\", \".join(right_pops)}', width=60)\n",
        "            plt.figtext(0.625, 0.03, wrapped_text, ha='center', va='top', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No data available for plotting.\")\n",
        "\n",
        "# Create the plot\n",
        "create_plot(plot_type)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d5U-qtcF0x2"
      },
      "source": [
        "# **[7] Mounting Drive and Saving Compressed Files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FwJ1vsWGEk7"
      },
      "source": [
        "To avoid the lengthy merging process in the future, we can mount our Google Drive and save any intermediate files and results using the code cell below. This will create a folder called **colabadmixtools** for you. Especially the merged dataset files (i.e. the .ind, .geno, .snp files). If you would like to do analysis on your merged data again in the future, just mount your drive using and specify the path of the compressed folder (Step 1 Option 3). After you mount, your drive should be at /content/drive/MyDrive within Colab. You will still need to perform Step 1 in the future but can then skip to Step 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FjmXl43TG3Bx"
      },
      "outputs": [],
      "source": [
        "# @title Mount Google Drive, Compress, and Save Files\n",
        "# @markdown Please mount your Google Drive, enter a name for the zipped folder, and then enter the paths of the files you want to save, separated by commas.\n",
        "zip_folder_name = \"Florio_merged\" #@param {type:\"string\"}\n",
        "file_paths = \"/content/Florio_merged1240K.geno,/content/Florio_merged1240K.ind,/content/Florio_merged1240K.snp,/content/Zaer_mergedHO.geno,/content/Zaer_mergedHO.ind,/content/Zaer_mergedHO.snp\" #@param {type:\"string\"}\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Ensure the user has provided a zip folder name\n",
        "if not zip_folder_name:\n",
        "    print(\"Please provide a name for the zipped folder.\")\n",
        "else:\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Path for the 'colabadmixtools' folder\n",
        "    new_folder_path = '/content/drive/MyDrive/colabadmixtools'\n",
        "    if not os.path.exists(new_folder_path):\n",
        "        os.makedirs(new_folder_path)\n",
        "        print(f\"Created folder: {new_folder_path}\")\n",
        "    else:\n",
        "        print(f\"Folder already exists: {new_folder_path}\")\n",
        "\n",
        "    # Define the path for the ZIP file using the user-provided name\n",
        "    zip_file_path = os.path.join(new_folder_path, f\"{zip_folder_name}.zip\")\n",
        "\n",
        "    # Split the user-entered file paths by commas and trim whitespace\n",
        "    file_paths_list = [path.strip() for path in file_paths.split(',')]\n",
        "\n",
        "    # Check if any file paths were entered\n",
        "    if not file_paths_list or file_paths_list == ['']:\n",
        "        print(\"No file paths entered. Please enter the paths of the files you want to save.\")\n",
        "    else:\n",
        "        # Create a ZIP file and add the specified files\n",
        "        with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path in file_paths_list:\n",
        "                if os.path.exists(file_path):\n",
        "                    # Add file to the ZIP archive\n",
        "                    zipf.write(file_path, os.path.basename(file_path))\n",
        "                    print(f\"Added '{file_path}' to the ZIP archive: {zip_folder_name}.zip\")\n",
        "                else:\n",
        "                    print(f\"File does not exist: {file_path}\")\n",
        "        print(f\"Files have been successfully compressed and saved to '{zip_file_path}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utilities**"
      ],
      "metadata": {
        "id": "tdtmteqehLSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EIGENSTRAT/PACKEDANCESTRYMAP to PLINK Conversion ( + Extraction)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **inpref**: Prefix of the input files.\n",
        "- **outpref**: Desired prefix for the PLINK output files.\n",
        "- **inds**: (Optional) Comma-separated list of individuals to extract. If provided, `pops` should be left empty.\n",
        "- **pops**: (Optional) Comma-separated list of populations to extract. If provided, `inds` should be left empty.\n",
        "- **verbose**: Choose whether to print progress updates.\n",
        "\n",
        "Ensure that you provide either `inds` or `pops`, but not both if extracting. WARNING: Conversion of very large datasets is not possible in the Colab runtime (as of now) - please try converting/extracting the populations (Group Labels/IDs) you deem necessary for further analysis to avoid crashing the runtime.\n"
      ],
      "metadata": {
        "id": "GTdgStWAhhh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the input files\n",
        "inpref = \"/content/Florio_merged\"  # @param {type:\"string\"}\n",
        "\n",
        "# Prefix of the PLINK output files\n",
        "outpref = \"/content/Test3\"  # @param {type:\"string\"}\n",
        "\n",
        "# Individuals to extract (comma-separated string)\n",
        "inds = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations to extract (comma-separated string)\n",
        "pops = \"Florio,IBS.DG,Surui.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Verbose option\n",
        "verbose = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse lists\n",
        "def parse_list(input_list):\n",
        "    if isinstance(input_list, str) and input_list:\n",
        "        # Split by commas and strip whitespace\n",
        "        return [item.strip() for item in input_list.split(',')]\n",
        "    return None\n",
        "\n",
        "# Parse the individuals and populations lists\n",
        "inds_list = parse_list(inds)\n",
        "pops_list = parse_list(pops)\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Activate the automatic conversion of pandas objects to R objects\n",
        "pandas2ri.activate()\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['inpref'] = inpref\n",
        "robjects.globalenv['outpref'] = outpref\n",
        "robjects.globalenv['inds'] = robjects.StrVector(inds_list) if inds_list else robjects.NULL\n",
        "robjects.globalenv['pops'] = robjects.StrVector(pops_list) if pops_list else robjects.NULL\n",
        "robjects.globalenv['verbose'] = verbose\n",
        "\n",
        "# Load necessary libraries and run the conversion\n",
        "robjects.r('''\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "\n",
        "# Retrieve the parameters passed from Python\n",
        "inpref <- get(\"inpref\", envir = .GlobalEnv)\n",
        "outpref <- get(\"outpref\", envir = .GlobalEnv)\n",
        "inds <- get(\"inds\", envir = .GlobalEnv)\n",
        "pops <- get(\"pops\", envir = .GlobalEnv)\n",
        "verbose <- get(\"verbose\", envir = .GlobalEnv)\n",
        "\n",
        "# Print the parameters to verify they are set correctly\n",
        "print(paste(\"Input prefix: \", inpref))\n",
        "print(paste(\"Output prefix: \", outpref))\n",
        "print(paste(\"Individuals: \", if (is.null(inds)) \"None\" else toString(inds)))\n",
        "print(paste(\"Populations: \", if (is.null(pops)) \"None\" else toString(pops)))\n",
        "print(paste(\"Verbose: \", verbose))\n",
        "\n",
        "# Run the conversion\n",
        "packedancestrymap_to_plink(\n",
        "  inpref = inpref,\n",
        "  outpref = outpref,\n",
        "  inds = inds,\n",
        "  pops = pops,\n",
        "  verbose = verbose\n",
        ")\n",
        "\n",
        "# Indicate completion\n",
        "print(\"Conversion complete. PLINK files are saved with the specified prefix.\")\n",
        "''')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LNkvVx1GhO29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PLINK to 23andMe Conversion (PLINK)**\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **plink_file**: Prefix of the PLINK input files without the extension.\n",
        "- **individual_id**: ID of the individual to be converted to 23andMe format.\n",
        "\n",
        "Ensure that the PLINK input files (.bed, .bim, .fam) are in the specified directory.\n"
      ],
      "metadata": {
        "id": "QiyOZ3U8hjid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# Check if PLINK is already downloaded\n",
        "if not os.path.isfile('plink'):\n",
        "    # Download PLINK\n",
        "    !wget --no-check-certificate https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n",
        "    !unzip plink_linux_x86_64_20231211.zip\n",
        "    !chmod +x plink\n",
        "else:\n",
        "    print(\"PLINK is already downloaded. Skipping download step.\")\n",
        "\n",
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the PLINK input files without the extension\n",
        "plink_file = \"/content/Test3\"  # @param {type:\"string\"}\n",
        "\n",
        "# ID of the individual to be converted to 23andMe format\n",
        "individual_id = \"Florio:Florio\"  # @param {type:\"string\"}\n",
        "\n",
        "# Read the .fam file to get family and individual IDs\n",
        "fam_file = f\"{plink_file}.fam\"\n",
        "fam_df = pd.read_csv(fam_file, delim_whitespace=True, header=None)\n",
        "\n",
        "# Check if the individual ID exists in the .fam file\n",
        "if individual_id not in fam_df[1].values:\n",
        "    raise ValueError(f\"Individual ID {individual_id} not found in {fam_file}.\")\n",
        "\n",
        "# Create filter.txt for the specified individual\n",
        "filter_txt_content = fam_df[fam_df[1] == individual_id][[0, 1]].to_string(header=False, index=False)\n",
        "with open(\"filter.txt\", \"w\") as file:\n",
        "    file.write(filter_txt_content)\n",
        "\n",
        "# Run PLINK command to convert to 23andMe format\n",
        "plink_command = f\"./plink --bfile {plink_file} --keep filter.txt --snps-only --recode 23 --out {individual_id}\"\n",
        "subprocess.run(plink_command, shell=True)\n",
        "\n",
        "# Clean up\n",
        "os.remove(\"filter.txt\")\n",
        "\n",
        "# Print the PLINK log file\n",
        "log_file = f\"{individual_id}.log\"\n",
        "if os.path.isfile(log_file):\n",
        "    with open(log_file, 'r') as file:\n",
        "        print(\"PLINK Log File:\")\n",
        "        print(file.read())\n",
        "\n",
        "# Determine the correct 23andMe format file\n",
        "possible_files = [f for f in os.listdir() if f.startswith(individual_id) and f.endswith('.txt')]\n",
        "if possible_files:\n",
        "    final_txt_file = possible_files[0]\n",
        "    print(f\"\\nFirst 15 lines of the 23andMe format file ({final_txt_file}):\")\n",
        "    with open(final_txt_file, 'r') as file:\n",
        "        for _ in range(15):\n",
        "            print(file.readline().strip())\n",
        "else:\n",
        "    print(f\"23andMe format file for {individual_id} not found.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ybK5Kl8FhVik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA or MDS Plot Creation (PLINK)**\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **plink_file**: Prefix of the PLINK input files without the extension.\n",
        "- **method**: Choose between 'pca' and 'mds' for the analysis.\n",
        "- **count**: Number of dimensions to extract (for MDS) or principal components to extract (for PCA).\n"
      ],
      "metadata": {
        "id": "mBia3xShh4en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Check if PLINK is already downloaded\n",
        "if not os.path.isfile('plink'):\n",
        "    # Download PLINK\n",
        "    !wget --no-check-certificate https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n",
        "    !unzip plink_linux_x86_64_20231211.zip\n",
        "    !chmod +x plink\n",
        "else:\n",
        "    print(\"PLINK is already downloaded. Skipping download step.\")\n",
        "\n",
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the PLINK input files without the extension\n",
        "plink_file = \"/content/Test3\"  # @param {type:\"string\"}\n",
        "\n",
        "# Choose between 'pca' and 'mds' for the analysis\n",
        "method = \"pca\"  # @param [\"pca\", \"mds\"]\n",
        "\n",
        "# Number of dimensions to extract (for MDS) or principal components to extract (for PCA)\n",
        "count = 25  # @param {type:\"number\"}\n",
        "\n",
        "# Figure size for the plot\n",
        "figsize_width = 27  # @param {type:\"slider\", min:5, max:50, step:1}\n",
        "figsize_height = 25  # @param {type:\"slider\", min:5, max:50, step:1}\n",
        "\n",
        "# Run PLINK command for PCA or MDS analysis\n",
        "if method == \"pca\":\n",
        "    plink_command = f\"./plink --bfile {plink_file} --pca {count} header tabs --out {plink_file}\"\n",
        "    subprocess.run(plink_command, shell=True)\n",
        "    eigenvec_file = f\"{plink_file}.eigenvec\"\n",
        "    eigenval_file = f\"{plink_file}.eigenval\"\n",
        "\n",
        "    # Read the eigenvec file\n",
        "    eigenvec_df = pd.read_csv(eigenvec_file, delim_whitespace=True)\n",
        "\n",
        "    # Plot PCA\n",
        "    plt.figure(figsize=(figsize_width, figsize_height), dpi=300)\n",
        "    sns.scatterplot(x=eigenvec_df.iloc[:, 2], y=eigenvec_df.iloc[:, 3], hue=eigenvec_df.iloc[:, 1], palette='deep', legend=False)\n",
        "\n",
        "    # Add sample labels\n",
        "    for i in range(len(eigenvec_df)):\n",
        "        plt.text(eigenvec_df.iloc[i, 2], eigenvec_df.iloc[i, 3], eigenvec_df.iloc[i, 1],\n",
        "                 fontsize=9, weight='bold', ha='right' if eigenvec_df.iloc[i, 2] > 0 else 'left',\n",
        "                 va='bottom' if eigenvec_df.iloc[i, 3] > 0 else 'top')\n",
        "\n",
        "    plt.title('PCA Plot', fontsize=16)\n",
        "    plt.xlabel('PC1', fontsize=14)\n",
        "    plt.ylabel('PC2', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the PCA data table of eigenvectors\n",
        "    print(\"Table of Eigenvectors:\")\n",
        "    display(eigenvec_df)\n",
        "\n",
        "elif method == \"mds\":\n",
        "    plink_command = f\"./plink --bfile {plink_file} --cluster --mds-plot {count} eigvals --out {plink_file}\"\n",
        "    subprocess.run(plink_command, shell=True)\n",
        "    mds_file = f\"{plink_file}.mds\"\n",
        "\n",
        "    # Read the mds file\n",
        "    mds_df = pd.read_csv(mds_file, delim_whitespace=True)\n",
        "\n",
        "    # Plot MDS\n",
        "    plt.figure(figsize=(figsize_width, figsize_height), dpi=300)\n",
        "    sns.scatterplot(x=mds_df.iloc[:, 3], y=mds_df.iloc[:, 4], hue=mds_df.iloc[:, 1], palette='deep', legend=False)\n",
        "\n",
        "    # Add sample labels\n",
        "    for i in range(len(mds_df)):\n",
        "        plt.text(mds_df.iloc[i, 3], mds_df.iloc[i, 4], mds_df.iloc[i, 1],\n",
        "                 fontsize=9, weight='bold', ha='right' if mds_df.iloc[i, 3] > 0 else 'left',\n",
        "                 va='bottom' if mds_df.iloc[i, 4] > 0 else 'top')\n",
        "\n",
        "    plt.title('MDS Plot', fontsize=16)\n",
        "    plt.xlabel('Dimension 1', fontsize=14)\n",
        "    plt.ylabel('Dimension 2', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the MDS data table\n",
        "    print(\"MDS Data Table:\")\n",
        "    display(mds_df)\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Invalid method selected. Choose either 'pca' or 'mds'.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yT_hez0ah5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compute Fst (AT2)**"
      ],
      "metadata": {
        "id": "woa3SQ8Zv5Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Input Parameters for Fst Computation**\n",
        "\n",
        "# Dataset prefix\n",
        "prefix = \"/content/Florio_merged\"  # @param {type:\"string\"}\n",
        "\n",
        "# Population 1 (comma-separated population labels or file path)\n",
        "pop1_input = \"Florio,Tunisia_Kerkouane_Punic_oAfrica1.SG,Gambian.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Population 2 (comma-separated population labels or file path)\n",
        "pop2_input = \"Mbuti.DG,Luxembourg_Mesolithic.AG,MXL.DG,Turkey_Southeast_Cayonu_PPN.SG,Hungary_Langobard_o2.AG,Iran_GanjDareh_Historic.AG,Greece_Logkas_MBA.SG,USA_CA_SantaRosa_7400BP.AG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Use bootstrapping? (If FALSE, block-jackknife resampling will be used)\n",
        "boot = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# Adjust pseudohaploid (set to False if you have pseudohaploid samples)\n",
        "adjust_pseudohaploid = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse population lists\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        # Split by commas and strip whitespace/quotes\n",
        "        return [pop.strip().strip(\"'\") for pop in poplist.split(',')]\n",
        "    return poplist\n",
        "\n",
        "# Parse the population lists\n",
        "pop1 = parse_poplist(pop1_input)\n",
        "pop2 = parse_poplist(pop2_input)\n",
        "\n",
        "# Import rpy2 for interfacing with R\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['pop1'] = robjects.StrVector(pop1)\n",
        "robjects.globalenv['pop2'] = robjects.StrVector(pop2)\n",
        "robjects.globalenv['boot'] = boot\n",
        "robjects.globalenv['adjust_pseudohaploid'] = adjust_pseudohaploid\n",
        "\n",
        "print(\"Input parameters set:\")\n",
        "print(f\"Dataset prefix: {prefix}\")\n",
        "print(f\"Population 1: {pop1}\")\n",
        "print(f\"Population 2: {pop2}\")\n",
        "print(f\"Bootstrapping: {boot}\")\n",
        "print(f\"Adjust pseudohaploid: {adjust_pseudohaploid}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MQTNDvT8ugF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Run Fst Computation**\n",
        "\n",
        "%%R\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "\n",
        "# Retrieve parameters from Python\n",
        "prefix <- get(\"prefix\", envir = .GlobalEnv)\n",
        "pop1 <- get(\"pop1\", envir = .GlobalEnv)\n",
        "pop2 <- get(\"pop2\", envir = .GlobalEnv)\n",
        "boot <- get(\"boot\", envir = .GlobalEnv)\n",
        "adjust_pseudohaploid <- get(\"adjust_pseudohaploid\", envir = .GlobalEnv)\n",
        "\n",
        "# Print parameters for verification\n",
        "cat(\"Prefix path:\", prefix, \"\\n\")\n",
        "cat(\"Population 1:\", toString(pop1), \"\\n\")\n",
        "cat(\"Population 2:\", toString(pop2), \"\\n\")\n",
        "cat(\"Bootstrapping:\", boot, \"\\n\")\n",
        "cat(\"Adjust pseudohaploid:\", adjust_pseudohaploid, \"\\n\")\n",
        "\n",
        "# Compute Fst directly from genotype files\n",
        "fst_results <- fst(\n",
        "  data = prefix,\n",
        "  pop1 = pop1,\n",
        "  pop2 = pop2,\n",
        "  boot = boot,\n",
        "  verbose = TRUE,\n",
        "  adjust_pseudohaploid = adjust_pseudohaploid\n",
        ")\n",
        "\n",
        "# Output Fst results\n",
        "print(\"Fst computation complete.\")\n",
        "print(fst_results, n = Inf)  # Ensures all rows are displayed\n",
        "\n",
        "# Save results to a CSV file for convenience\n",
        "write.csv(fst_results, \"fst_results.csv\", row.names = FALSE)\n",
        "\n",
        "cat(\"Fst results saved to fst_results.csv.\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5cIMK4qMwenV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Admixture Graphs (AT2)**"
      ],
      "metadata": {
        "id": "rEWag33Z2qms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Admixture Graph Input Parameters**\n",
        "\n",
        "# Dataset prefix for f-statistics\n",
        "prefix = \"/content/Florio_merged\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations for admixture graph (comma-separated or user input)\n",
        "populations_input = \"Florio,Tunisia_Kerkouane_Punic_oAfrica1.SG,Gambian.DG,Mbuti.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Number of admixture edges for find_graphs\n",
        "numadmix = 3  # @param {type:\"integer\"}\n",
        "\n",
        "# Output population for graph root\n",
        "outpop = \"Mbuti.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Stop generation for find_graphs\n",
        "stop_gen = 25  # @param {type:\"integer\"}\n",
        "\n",
        "# Function to parse the population list\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        return [pop.strip() for pop in poplist.split(\",\")]\n",
        "    return poplist\n",
        "\n",
        "# Parse user-specified populations\n",
        "populations = parse_poplist(populations_input)\n",
        "\n",
        "# Pass parameters to R environment\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['populations'] = robjects.StrVector(populations)\n",
        "robjects.globalenv['numadmix'] = numadmix\n",
        "robjects.globalenv['outpop'] = outpop\n",
        "robjects.globalenv['stop_gen'] = stop_gen\n",
        "\n",
        "print(\"Input parameters set:\")\n",
        "print(f\"Prefix: {prefix}\")\n",
        "print(f\"Populations: {populations}\")\n",
        "print(f\"Number of admixture edges: {numadmix}\")\n",
        "print(f\"Outgroup population: {outpop}\")\n",
        "print(f\"Stop generation: {stop_gen}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PSaBVczG2xTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Run Admixture Graph Analysis**\n",
        "\n",
        "%%R\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "library(plotly)\n",
        "\n",
        "# Retrieve parameters\n",
        "prefix <- get(\"prefix\", envir = globalenv())\n",
        "populations <- get(\"populations\", envir = globalenv())\n",
        "numadmix <- get(\"numadmix\", envir = globalenv())\n",
        "outpop <- get(\"outpop\", envir = globalenv())\n",
        "stop_gen <- get(\"stop_gen\", envir = globalenv())\n",
        "\n",
        "# Print parameters for verification\n",
        "cat(\"Prefix path:\", prefix, \"\\n\")\n",
        "cat(\"Populations:\", toString(populations), \"\\n\")\n",
        "cat(\"Number of admixture edges:\", numadmix, \"\\n\")\n",
        "cat(\"Outgroup population:\", outpop, \"\\n\")\n",
        "cat(\"Stop generation:\", stop_gen, \"\\n\")\n",
        "\n",
        "# Compute f2 blocks from the dataset\n",
        "cat(\"Computing f2 blocks...\\n\")\n",
        "f2_blocks <- f2_from_geno(prefix, pops = populations)\n",
        "\n",
        "# Automated graph exploration\n",
        "cat(\"Finding optimal graphs...\\n\")\n",
        "opt_results <- find_graphs(f2_blocks, numadmix = numadmix, outpop = outpop, stop_gen = stop_gen)\n",
        "\n",
        "# Extract the best graph\n",
        "winner <- opt_results %>% slice_min(score, with_ties = FALSE)\n",
        "\n",
        "# Display best graph score\n",
        "best_score <- winner$score[[1]]\n",
        "cat(\"Best graph score:\", best_score, \"\\n\")\n",
        "\n",
        "# Plot the best graph interactively\n",
        "cat(\"Visualizing the best graph...\\n\")\n",
        "best_graph <- winner$edges[[1]]\n",
        "\n",
        "# Use plotly to create and display an interactive graph\n",
        "interactive_plot <- plotly_graph(best_graph, fix = TRUE)\n",
        "\n",
        "# Save the graph edges and scores\n",
        "write.csv(best_graph, \"best_graph_edges.csv\", row.names = FALSE)\n",
        "cat(\"Best graph edges saved to best_graph_edges.csv.\\n\")\n",
        "\n",
        "# Output the plot for Jupyter Notebook\n",
        "interactive_plot\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WfF7qRF_63Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to check and install required packages\n",
        "def install_and_import(package_name, package_alias=None):\n",
        "    try:\n",
        "        __import__(package_alias or package_name)\n",
        "    except ImportError:\n",
        "        print(f\"Package '{package_name}' not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "\n",
        "# Ensure required packages are installed\n",
        "install_and_import(\"python-igraph\", \"igraph\")\n",
        "install_and_import(\"matplotlib\")\n",
        "\n",
        "# Import igraph after ensuring it is installed\n",
        "from igraph import Graph, plot\n",
        "\n",
        "# Define custom parameters as form fields\n",
        "# Path to the graph file (CSV)\n",
        "graph_file = \"best_graph_edges.csv\"  # @param {type:\"string\"}\n",
        "\n",
        "# Edge width for connections\n",
        "edge_width = 2  # @param {type:\"slider\", min:0.5, max:10, step:0.1}\n",
        "\n",
        "# Font size for node labels\n",
        "font_size = 8  # @param {type:\"slider\", min:8, max:40, step:1}\n",
        "\n",
        "# Layout type (options: \"tree\" or \"kk\")\n",
        "layout_type = \"tree\"  # @param [\"tree\", \"kk\"]\n",
        "\n",
        "# Round percentages to this number of decimal places\n",
        "decimal_places = 1  # @param {type:\"slider\", min:0, max:3, step:1}\n",
        "\n",
        "# Plot dimensions\n",
        "plot_width = 20  # @param {type:\"slider\", min:10, max:100, step:1}\n",
        "plot_height = 12  # @param {type:\"slider\", min:10, max:100, step:1}\n",
        "\n",
        "# Background color\n",
        "background_color = \"white\"  # @param [\"white\", \"lightgray\", \"black\"]\n",
        "\n",
        "# Edge color\n",
        "edge_color = \"darkgray\"  # @param [\"darkgray\", \"black\", \"blue\", \"red\"]\n",
        "\n",
        "# Text color\n",
        "text_color = \"black\"  # @param [\"black\", \"white\", \"blue\", \"red\"]\n",
        "\n",
        "# Function to plot the admixture graph\n",
        "def plot_admixture_graph(graph_file, edge_width, font_size, layout_type, decimal_places, plot_width, plot_height, background_color, edge_color, text_color):\n",
        "    if not os.path.isfile(graph_file):\n",
        "        print(f\"Error: File '{graph_file}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Load edges from CSV\n",
        "    edges_df = pd.read_csv(graph_file)\n",
        "\n",
        "    # Create igraph object\n",
        "    g = Graph(directed=True)\n",
        "    g.add_vertices(list(set(edges_df[\"from\"].tolist() + edges_df[\"to\"].tolist())))\n",
        "    g.add_edges(zip(edges_df[\"from\"], edges_df[\"to\"]))\n",
        "\n",
        "    # Set layout\n",
        "    if layout_type == \"tree\":\n",
        "        layout = g.layout(\"rt\")\n",
        "    else:\n",
        "        layout = g.layout(\"kk\")\n",
        "\n",
        "    # Prepare vertex labels with rounded contributions\n",
        "    vertex_labels = []\n",
        "    for vertex in g.vs:\n",
        "        if vertex[\"name\"] in edges_df[\"to\"].values:\n",
        "            contribution = edges_df[edges_df[\"to\"] == vertex[\"name\"]][[\"from\", \"weight\"]]\n",
        "            contribution[\"weight\"] = contribution[\"weight\"].apply(lambda x: round(x * 100, decimal_places))  # Round\n",
        "            label = f\"{vertex['name']} ({', '.join(contribution['from'] + ': ' + contribution['weight'].astype(str) + '%')})\"\n",
        "            vertex_labels.append(label)\n",
        "        else:\n",
        "            vertex_labels.append(vertex[\"name\"])\n",
        "\n",
        "    # Dynamically calculate figure size based on layout\n",
        "    layout_coords = layout.coords  # Extract the coordinates\n",
        "    x_coords = [coord[0] for coord in layout_coords]\n",
        "    y_coords = [coord[1] for coord in layout_coords]\n",
        "    dynamic_width = max(x_coords) - min(x_coords)\n",
        "    dynamic_height = max(y_coords) - min(y_coords)\n",
        "    fig_width = max(dynamic_width / 2, plot_width)  # Scale width appropriately\n",
        "    fig_height = max(dynamic_height / 2, plot_height)  # Scale height appropriately\n",
        "\n",
        "    # Plot the graph\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "    ax.set_facecolor(background_color)  # Set background color\n",
        "    plot(\n",
        "        g,\n",
        "        layout=layout,\n",
        "        target=ax,\n",
        "        vertex_size=0,  # No default circles\n",
        "        vertex_label=vertex_labels,\n",
        "        vertex_label_size=font_size,\n",
        "        vertex_label_dist=0.5,  # Increase label distance from nodes\n",
        "        vertex_label_color=text_color,  # Set text color\n",
        "        vertex_label_fontweight=\"bold\",  # Bold text\n",
        "        edge_width=edge_width,\n",
        "        edge_color=edge_color,\n",
        "        bbox=None,  # Autoscale the graph\n",
        "        margin=max(dynamic_height / 10, 10),  # Dynamic margin\n",
        "    )\n",
        "    plt.title(\"Admixture Graph with Contributions\", fontsize=font_size + 4, fontweight=\"bold\", color=text_color)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with user-defined parameters\n",
        "plot_admixture_graph(\n",
        "    graph_file,\n",
        "    edge_width,\n",
        "    font_size,\n",
        "    layout_type,\n",
        "    decimal_places,\n",
        "    plot_width,\n",
        "    plot_height,\n",
        "    background_color,\n",
        "    edge_color,\n",
        "    text_color\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cl9SjKASFrqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}