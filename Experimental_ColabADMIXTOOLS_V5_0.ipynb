{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agonist11/colabadmixtools/blob/main/Experimental_ColabADMIXTOOLS_V5_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04iVpOTvZI7"
      },
      "source": [
        "# **ColabADMIXTOOLS Version 5.0**\n",
        "This notebook is designed to make it easier for people to model themselves (or just the AADR) using ADMIXTOOLS/ADMIXTOOLS2 (which includes qpAdm) with curated datasets. This notebook uses the AADR dataset from [here](https://reich.hms.harvard.edu/allen-ancient-dna-resource-aadr-downloadable-genotypes-present-day-and-ancient-dna-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Gkz5Uux8-l"
      },
      "source": [
        "You will need a Google account to be able to use Google Colaboratory. If you recieved this as a link, please make a copy for yourself using the **'File'** tab. If you received this a .ipynb, upload this notebook using the **'File'** tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Gy9JnoyqEE"
      },
      "source": [
        "Once the notebook is loaded, click **Connect** (top-right) to connect to a hosted runtime. CPU option should work fine with merging to the HO or just running AADR. To merge with 1240K, try v2-8 TPU runtime. We will be borrowing storage and a CPU from Google. As a result, nothing will be saved once you disconnect from the session. However, you may use the Colab File Explorer (left sidebar under security key) to view, open, and download intermediate or final results. See Step 7 to save any datasets to your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please visit Florio's GitHub Repo [Here](https://github.com/agonist11/colabadmixtools/) for a QuickStart Guide.**"
      ],
      "metadata": {
        "id": "jGIm5US6dDUz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtePdSNjCQ1U"
      },
      "source": [
        "# **[1] Install Software**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup Script for ADMIXTOOLS & ADMIXTOOLS2**\n",
        "This guide explains the parameters and installation process for **ADMIXTOOLS**, **ADMIXTOOLS2**, **PLINK**, and other dependencies.\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Installation Preferences**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `install_admixtools` | `True` | If `True`, installs **ADMIXTOOLS** (DReichLab version) for f-statistics analysis. |\n",
        "| `install_admixtools2` | `True` | If `True`, installs **ADMIXTOOLS 2**, an R-based implementation of f-statistics tools. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÇ Dataset & SNP List Management**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `repo_url` | `\"https://github.com/agonist11/colabadmixtools/raw/main/\"` | GitHub repository where **SNP list files** are stored. |\n",
        "| `snplist_files` | `[\"1240Ksnplistv62.snplist\", \"HOsnplistv62.snplist\"]` | List of **SNP files** to be downloaded. |\n",
        "| `snplist_dir` | `\"/content\"` | Directory where **SNP lists** are saved. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üì• SNP List Download**\n",
        "- If the required **SNP lists** (`1240Ksnplistv62.snplist`, `HOsnplistv62.snplist`) **do not exist**, they are **downloaded** from the GitHub repository.\n",
        "---\n",
        "\n",
        "### **üñ•Ô∏è Installing Dependencies**\n",
        "| **Dependency** | **Installation Command** | **Description** |\n",
        "|--------------|------------------------|----------------|\n",
        "| **R** | `sudo apt-get install -y r-base` | Installs R if not already available. |\n",
        "| **rpy2** | `pip install rpy2` | Installs `rpy2` for running R inside Python (if not installed). |\n",
        "| **PLINK** | `wget ... plink.zip && unzip` | Downloads and installs **PLINK** for genetic analysis. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Notes**\n",
        "- **SNP lists** are downloaded **once** and are skipped if already present.\n",
        "- If `install_admixtools = False`, **ADMIXTOOLS 1 will not be installed**.\n",
        "- If `install_admixtools2 = False`, **ADMIXTOOLS2 (R) will not be installed**.\n"
      ],
      "metadata": {
        "id": "JcnMR_F1chvv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QTN1OE0F_Kqj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from subprocess import run, PIPE\n",
        "\n",
        "# @markdown **Select your preferences for the setup process. If asked to update dependencies, skip them by pressing Enter button**\n",
        "install_admixtools = True  # @param {type:\"boolean\"}\n",
        "install_admixtools2 = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# GitHub repository location\n",
        "repo_url = \"https://github.com/agonist11/colabadmixtools/raw/main/\"\n",
        "snplist_files = [\"1240Ksnplistv62.snplist\", \"HOsnplistv62.snplist\"]\n",
        "\n",
        "# Function to check if a command exists\n",
        "def command_exists(command):\n",
        "    return run(['which', command], stdout=PIPE, stderr=PIPE).returncode == 0\n",
        "\n",
        "# Create a folder for SNP lists\n",
        "snplist_dir = \"/content\"\n",
        "os.makedirs(snplist_dir, exist_ok=True)\n",
        "\n",
        "# Download SNP lists from GitHub\n",
        "for snplist in snplist_files:\n",
        "    snplist_url = repo_url + snplist\n",
        "    snplist_path = os.path.join(snplist_dir, snplist)\n",
        "\n",
        "    if not os.path.exists(snplist_path):\n",
        "        print(f\"Downloading {snplist} from GitHub...\")\n",
        "        !wget -q -O {snplist_path} {snplist_url}\n",
        "    else:\n",
        "        print(f\"{snplist} already exists.\")\n",
        "\n",
        "print(\"SNP lists downloaded and saved in /content\")\n",
        "\n",
        "# Install R if not installed\n",
        "if not command_exists('R'):\n",
        "    print(\"Installing R...\")\n",
        "    !sudo apt-get update -y\n",
        "    !sudo apt-get install -y r-base\n",
        "else:\n",
        "    print(\"R is already installed.\")\n",
        "\n",
        "# Install rpy2 if not already installed\n",
        "try:\n",
        "    import rpy2\n",
        "    print(\"rpy2 is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"Installing rpy2...\")\n",
        "    !pip install rpy2\n",
        "\n",
        "# Load rpy2 extension\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "# Check for PLINK\n",
        "if not os.path.exists('/content/plink'):\n",
        "    print(\"Installing PLINK...\")\n",
        "    !wget https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20241022.zip -O plink.zip\n",
        "    !unzip -o plink.zip -d /content/\n",
        "    os.remove(\"plink.zip\")\n",
        "    print(\"PLINK installation complete!\")\n",
        "else:\n",
        "    print(\"PLINK is already installed.\")\n",
        "\n",
        "# Check and install ADMIXTOOLS\n",
        "if install_admixtools:\n",
        "    if not os.path.exists('/content/AdmixTools'):\n",
        "        print(\"Installing ADMIXTOOLS...\")\n",
        "        !apt-get update\n",
        "        !apt-get install -y build-essential libgsl-dev libopenblas-dev gfortran liblapacke-dev \\\n",
        "                           libssl-dev libffi-dev libncurses5-dev zlib1g zlib1g-dev \\\n",
        "                           libreadline-dev libbz2-dev libsqlite3-dev\n",
        "        !rm -rf AdmixTools\n",
        "        !git clone https://github.com/DReichLab/AdmixTools.git\n",
        "        %cd AdmixTools/src\n",
        "        !sed -i \"s/-Wimplicit/-Wimplicit -fcommon/\" Makefile\n",
        "        !make clobber\n",
        "        !make all LDLIBS=\"-llapacke -llapack -lgsl -lopenblas -lm -lnick\"\n",
        "        !make install\n",
        "        %cd /content/\n",
        "        print(\"ADMIXTOOLS installation complete!\")\n",
        "    else:\n",
        "        print(\"ADMIXTOOLS is already installed.\")\n",
        "\n",
        "# Check and install ADMIXTOOLS2\n",
        "if install_admixtools2:\n",
        "    try:\n",
        "        import rpy2.robjects as ro\n",
        "        print(\"Checking for ADMIXTOOLS2 installation...\")\n",
        "        ro.r('''\n",
        "        if (!requireNamespace(\"admixtools\", quietly = TRUE)) {\n",
        "            stop(\"ADMIXTOOLS2 is not installed.\")\n",
        "        }\n",
        "        ''')\n",
        "        print(\"ADMIXTOOLS2 is already installed.\")\n",
        "    except Exception as e:\n",
        "        print(\"Installing ADMIXTOOLS2...\")\n",
        "        ro.r('''\n",
        "        lib_path <- \"/usr/local/lib/R/site-library\"\n",
        "        install.packages(\"remotes\", lib = lib_path)\n",
        "        remotes::install_github(\"uqrmaie1/admixtools\", dependencies = TRUE, lib = lib_path)\n",
        "        ''')\n",
        "        print(\"ADMIXTOOLS2 installation complete!\")\n",
        "\n",
        "print(\"Setup complete! SNP lists are available in /content\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeSp0z3LVWq"
      },
      "source": [
        "**Both PLINK and rpy2 will be installed in any scenario. ADMIXTOOLS (AT1) installation is faster but model computation is slower. ADMIXTOOLS2 (AT2) installation is slower but model computation is faster. We recommend exploration and rotation strategy with AT2 and cross-referencing with AT1 afterwards (see Step 5 and Utility 6).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irfC9KGv0dWw"
      },
      "source": [
        "# **[2] Your DNA File Upload**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79PipZkXM0YG"
      },
      "source": [
        "**If you only want to model samples within the AADR you may skip this section and move to [3] Dataset Selection.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DNA File Processing & Google Drive Management**\n",
        "This script allows users to **upload, extract, copy, and convert** genomic files for use with **qpAdm** and other ADMIXTOOLS analyses.\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÇ File Handling & Operations**\n",
        "| **Operation** | **Description** |\n",
        "|--------------|----------------|\n",
        "| `1. Upload 23andMe File` | Uploads a **23andMe DNA file** to Colab. |\n",
        "| `2. Upload & Convert AncestryDNA File` | Uploads and **converts AncestryDNA** format to **23andMe format**. |\n",
        "| `3. Mount & Extract ZIP File` | Mounts **Google Drive** and extracts **a ZIP archive**. |\n",
        "| `4. Mount & Copy SNP Lists` | Mounts Google Drive and **copies SNP list files** for analysis. |\n",
        "| `5. Convert DNA File to 23andMe Format` | Converts **MyHeritage, FTDNA, or AncestryDNA files** to **23andMe format**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üîÑ File Conversion Parameters**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `input_file` | `\"/content/MyHeritage_Example_dna_data.csv\"` | Path to the **DNA file** to be converted. |\n",
        "| `input_format` | `\"myheritage\"` | Input format: **23andme, ancestry, myheritage, ftdnav1, ftdnav2**. |\n",
        "| `output_file` | `\"MHconverted_23andme.txt\"` | Name of the converted output file. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Google Drive & File Management**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `zip_folder_path` | `\"/content/drive/MyDrive/colabadmixtools/Example_mergedHO.zip\"` | Path to a ZIP file for extraction. For those returning and already performed Step 7 below. |\n",
        "| `snp_list_folder_path` | `\"/content/drive/MyDrive/colabadmixtools/snplists\"` | Path to a folder containing **SNP lists**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **‚úÖ Notes**\n",
        "- **Google Drive must be mounted** for ZIP extraction and SNP file copying.\n",
        "- The script **automatically detects the user-selected operation** and runs the appropriate function.\n",
        "- **File format conversion** ensures compatibility with ADMIXTOOLS.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qWNT-JMeeYCK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSmLy92EKmAT"
      },
      "source": [
        "**23andMe formatted data works best for conversion. Please explore [DNA Kit Studio](https://www.dnagenics.com/dna-kit-studio/) on how to make this conversion possible. Some users have also found success with [this](https://tendna.com/en/dna-converter) converter as well.**\n",
        "\n",
        "**Select Operation 1 from the dropdown and run the code cell to upload your 23andMe file. Select Operation 2 to upload AncestryDNA and convert it. Select Operation 3 if you are returning and you did Step 7 previously. Select Operation 4 if you have different snplists to upload from your Drive. Select Operation 5 if you have MyHeritage or FTDNA and fill in the rest before running the code cell.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import files, drive\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "#@markdown ## **Choose an Operation**\n",
        "operation = \"3. Mount & Extract ZIP File\"  #@param [\"1. Upload 23andMe File\", \"2. Upload & Convert AncestryDNA File\", \"3. Mount & Extract ZIP File\", \"4. Mount & Copy SNP Lists\", \"5. Convert DNA File to 23andMe Format\"]\n",
        "\n",
        "# Upload and process genome files\n",
        "def upload_genome(file_type=\"23andMe\"):\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        filename = next(iter(uploaded))\n",
        "        print(f\"File '{filename}' uploaded successfully.\")\n",
        "        if file_type == \"AncestryDNA\":\n",
        "            process_ancestry_file(filename)\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "\n",
        "# Convert AncestryDNA to 23andMe format\n",
        "def convert_ancestry_to_23andme(content):\n",
        "    lines = content.strip().split(\"\\n\")\n",
        "    header_end_idx = next(i for i, line in enumerate(lines) if line.startswith(\"rsid\"))\n",
        "    data_lines = lines[header_end_idx+1:]\n",
        "\n",
        "    converted_lines = [\"# rsid\\tchromosome\\tposition\\tgenotype\"]\n",
        "    for line in data_lines:\n",
        "        parts = line.split(\"\\t\")\n",
        "        if len(parts) == 5:\n",
        "            rsid, chromosome, position, allele1, allele2 = parts\n",
        "            genotype = allele1 + allele2\n",
        "            converted_lines.append(f\"{rsid}\\t{chromosome}\\t{position}\\t{genotype}\")\n",
        "\n",
        "    return \"\\n\".join(converted_lines)\n",
        "\n",
        "# Process AncestryDNA file\n",
        "def process_ancestry_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    if \"AncestryDNA raw data download\" in content:\n",
        "        print(f\"Converting '{filename}' to 23andMe format...\")\n",
        "        converted_content = convert_ancestry_to_23andme(content)\n",
        "        converted_filename = filename.replace(\".txt\", \"_converted.txt\")\n",
        "\n",
        "        with open(converted_filename, \"w\") as f:\n",
        "            f.write(converted_content)\n",
        "\n",
        "        print(f\"File converted and saved as '{converted_filename}'.\")\n",
        "    else:\n",
        "        print(f\"File '{filename}' does not appear to be in AncestryDNA format.\")\n",
        "\n",
        "#@markdown **Operation 3. Path to ZIP file (if extracting, otherwise leave blank):**\n",
        "zip_folder_path = \"/content/drive/MyDrive/colabadmixtools/Example_mergedHO.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "# Mount Google Drive and extract ZIP files\n",
        "def mount_and_extract(zip_folder_path):\n",
        "    drive.mount('/content/drive')\n",
        "    zip_file_path = os.path.join('/content/drive/MyDrive/', zip_folder_path)\n",
        "\n",
        "    if os.path.exists(zip_file_path) and zip_file_path.endswith('.zip'):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "            print(f\"Contents of '{zip_folder_path}' extracted to '/content/'\")\n",
        "    else:\n",
        "        print(f\"Zip file not found at '{zip_folder_path}'.\")\n",
        "\n",
        "#@markdown **Operation 4. Path to SNP list folder (if copying SNPs, otherwise leave blank):**\n",
        "snp_list_folder_path = \"/content/drive/MyDrive/colabadmixtools/snplists\"  #@param {type:\"string\"}\n",
        "\n",
        "# Mount Google Drive and copy SNP lists\n",
        "def mount_and_copy_snp_lists(snp_list_folder_path):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    if os.path.exists(snp_list_folder_path) and os.path.isdir(snp_list_folder_path):\n",
        "        destination_folder = '/content/'\n",
        "        os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "        for item in os.listdir(snp_list_folder_path):\n",
        "            source = os.path.join(snp_list_folder_path, item)\n",
        "            destination = os.path.join(destination_folder, item)\n",
        "            if os.path.isfile(source):\n",
        "                shutil.copy2(source, destination)\n",
        "            elif os.path.isdir(source):\n",
        "                shutil.copytree(source, destination, dirs_exist_ok=True)\n",
        "\n",
        "        print(f\"Contents of '{snp_list_folder_path}' copied to '{destination_folder}'\")\n",
        "    else:\n",
        "        print(f\"Folder not found at '{snp_list_folder_path}'.\")\n",
        "\n",
        "# Set up and run terraseq DNA file conversion\n",
        "def setup_terraseq():\n",
        "    terraseq_url = \"https://github.com/enelsr/terraseq/releases/latest/download/terraseq\"\n",
        "    os.system(f\"wget -O terraseq {terraseq_url}\")\n",
        "    os.system(\"chmod +x terraseq\")\n",
        "    print(\"terraseq setup completed successfully.\")\n",
        "\n",
        "#@markdown **Operation 5. Specify the file path of your DNA file (if converting from MyHeritage or FTDNA, otherwise leave blank):**\n",
        "input_file = \"/content/MyHeritage_Example_dna_data.csv\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Select the input file format (for Operation 5: otherwise do not change):**\n",
        "input_format = \"myheritage\"  #@param [\"23andme\", \"ancestry\", \"myheritage\", \"ftdnav1\", \"ftdnav2\"]\n",
        "\n",
        "#@markdown **Specify the output file name (for Operation 5, otherwise leave blank):**\n",
        "output_file = \"MHconverted_23andme.txt\"  #@param {type:\"string\"}\n",
        "\n",
        "def convert_dna_file(input_file, input_format, output_file):\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"Error: The file path '{input_file}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Converting {input_file} from {input_format} to 23andMe format...\")\n",
        "    command = f\"./terraseq convert --inFile {input_file} --inFormat {input_format} --outFormat 23andme --outFile {output_file}\"\n",
        "    os.system(command)\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Conversion successful! Output file: {output_file}\")\n",
        "    else:\n",
        "        print(\"Conversion failed. Please check your input file and format.\")\n",
        "\n",
        "# **Execution Logic Based on User Selection**\n",
        "if operation == \"1. Upload 23andMe File\":\n",
        "    upload_genome(\"23andMe\")\n",
        "\n",
        "elif operation == \"2. Upload & Convert AncestryDNA File\":\n",
        "    upload_genome(\"AncestryDNA\")\n",
        "\n",
        "elif operation == \"3. Mount & Extract ZIP File\":\n",
        "    mount_and_extract(zip_folder_path)\n",
        "\n",
        "elif operation == \"4. Mount & Copy SNP Lists\":\n",
        "    mount_and_copy_snp_lists(snp_list_folder_path)\n",
        "\n",
        "elif operation == \"5. Convert DNA File to 23andMe Format\":\n",
        "    setup_terraseq()\n",
        "    convert_dna_file(input_file, input_format, output_file)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DcrAmuXoxhHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkPECXj-JpyI"
      },
      "source": [
        "**If you do not have the snplists, modeling your sample can lead to high Standard Errors. Please ask whoever sent you this notebook to provide you the snplists. Then use the Optional Step above if it is in your Google Drive or manually upload them to this session using the Upload function on the left.**\n",
        "\n",
        "**Update: By running Step 1, you should already have the snplists downloaded already now and visible in the colab File Explorer.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIHcUfjY1DV7"
      },
      "source": [
        "# **[3] Dataset Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Am_c6ONKLn"
      },
      "source": [
        "**The 1240K has more coverage than the 1240K+HO. However, the 1240K+HO has more modern samples. You can download one after the other if you would like to explore both datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download 1240K or HO Datasets (AADR v62)**\n",
        "This script downloads **ancient DNA reference datasets** from the **Allen Ancient DNA Resource (AADR v62)**.\n",
        "\n",
        "### **üìå Dataset Options**\n",
        "| **Option** | **Files Downloaded** |\n",
        "|-----------|----------------------|\n",
        "| `1240K` | 1240K dataset (geno, ind, snp, anno, Excel) |\n",
        "| `1240K+HO` | 1240K + Human Origins dataset (geno, ind, snp, anno, Excel) |\n",
        "\n",
        "### **üîΩ How It Works**\n",
        "- **Select a dataset** (`1240K` or `1240K+HO`).\n",
        "- Downloads the corresponding files from **Harvard Dataverse**.\n",
        "- Saves them in `/content/`.\n",
        "\n",
        "### **‚úÖ Notes**\n",
        "- Ensure enough storage space before downloading.\n",
        "- Files will be stored in **Colab‚Äôs workspace**.\n"
      ],
      "metadata": {
        "id": "nTjIb3xJfiYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e-9bhlIJvT1o"
      },
      "outputs": [],
      "source": [
        "# @title **Download 1240K or HO Datasets (AADR v62)**\n",
        "# @markdown Select the dataset you want to download:\n",
        "\n",
        "dataset_choice = \"1240K+HO\" #@param [\"1240K\", \"1240K+HO\"]\n",
        "\n",
        "# Define the URLs and corresponding filenames for each dataset\n",
        "dataset_files = {\n",
        "    \"1240K\": [\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537413\", \"aadr_v62.0_1240K_public.anno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537126\", \"aadr_v62.0_1240K_public.geno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537414\", \"aadr_v62.0_1240K_public.ind\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537415\", \"aadr_v62.0_1240K_public.snp\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537416\", \"v62.0_1240K_public.xlsx\")\n",
        "    ],\n",
        "    \"1240K+HO\": [\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537417\", \"aadr_v62.0_HO_public.anno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537419\", \"aadr_v62.0_HO_public.geno\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537420\", \"aadr_v62.0_HO_public.ind\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537421\", \"aadr_v62.0_HO_public.snp\"),\n",
        "        (\"https://dataverse.harvard.edu/api/access/datafile/10537422\", \"v62.0_HO_public.xlsx\")\n",
        "    ]\n",
        "}\n",
        "\n",
        "selected_files = dataset_files[dataset_choice]\n",
        "\n",
        "print(f\"Downloading {dataset_choice} dataset files...\")\n",
        "for url, filename in selected_files:\n",
        "    !wget --no-check-certificate {url} -O /content/{filename}\n",
        "\n",
        "print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV2BriRHOM50"
      },
      "source": [
        "**Look for the associated .xlsx spreadsheet on the left File Explorer to look at all the samples in the dataset. When modeling, we refer to the Group ID, which may contain one or more samples.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DQIkKnjPSIl"
      },
      "source": [
        "# **[4] Merging Yourself with the AADR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jKui3wT9vvk"
      },
      "source": [
        "#### **You can skip to Step 5 if you just want to model within the AADR. For now, only merging with the +HO dataset is possible on a regular CPU Python 3 runtime. Change runtime to TPU v2-8 to merge with the 1240K.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Processing & Merging**\n",
        "This script **converts, trims, and merges** a **23andMe** genetic file with reference datasets for use in **ADMIXTOOLS**.\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÇ Input Parameters**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `genome_filepath` | `\"/content/merged_Example_genome.txt\"` | Path to the **23andMe TXT file**. |\n",
        "| `output_base` | `\"Example\"` | Prefix for output files. |\n",
        "| `sex_code` | `\"1\"` | Defines the **sex in .fam file** (1 = male, 2 = female, 0 = unknown). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üîç Optional Settings**\n",
        "| **Option** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `trim_with_snplist` | `True` | If `True`, trims the dataset using a **SNP list**. |\n",
        "| `snplist_path` | `\"/content/HOsnplistv62.snplist\"` | Path to the **SNP list** (if trimming is enabled). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üîó Dataset Merging Parameters**\n",
        "| **Parameter** | **Example** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `geno1_path` | `\"/content/aadr_v62.0_HO_public.geno\"` | First dataset **geno file**. |\n",
        "| `snp1_path` | `\"/content/aadr_v62.0_HO_public.snp\"` | First dataset **snp file**. |\n",
        "| `ind1_path` | `\"/content/aadr_v62.0_HO_public.ind\"` | First dataset **ind file**. |\n",
        "| `num_threads` | `2` | Number of threads for **mergeit**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üõ†Ô∏è Process Overview**\n",
        "1. **Creates Swap Memory** to prevent out-of-memory errors.\n",
        "2. **Converts 23andMe file** to **PLINK format**.\n",
        "3. **Updates the .fam file** with correct metadata.\n",
        "4. **Trims dataset** using a SNP list (if enabled).\n",
        "5. **Converts PLINK data** to **PACKEDANCESTRYMAP format**.\n",
        "6. **Merges dataset** with AADR Dataset files.\n",
        "7. **Verifies merged dataset**.\n",
        "\n",
        "---\n",
        "\n",
        "### **‚úÖ Notes**\n",
        "- If `trim_with_snplist = True`, the **SNP list must be provided**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "aWeoRbIwg13V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4cDNUPDEU0O6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# @markdown ### Step 1: Specify Inputs\n",
        "\n",
        "# @markdown **Filepath to your 23andMe TXT File**:\n",
        "genome_filepath = \"/content/merged_Florio_genome.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Output Base Prefix**: Define a name for intermediate and final files.\n",
        "output_base = \"Florio\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **.fam File Parameters**:\n",
        "# @markdown These fields will auto-fill based on `output_base`, but you can edit `sex_code` as needed.\n",
        "family_id = output_base  # Automatically set to output_base\n",
        "individual_id = output_base  # Automatically set to output_base\n",
        "father_id = '0'  # Always 0\n",
        "mother_id = '0'  # Always 0\n",
        "sex_code = '1'  # @param [\"1\", \"2\", \"0\"]  # Default is 1 (male)\n",
        "phenotype_value = '0'  # Always 0\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Trim Using SNP List?**\n",
        "trim_with_snplist = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **If Trimming**, specify:\n",
        "snplist_path = \"/content/HOsnplistv62.snplist\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Merge Dataset Parameters\n",
        "# @markdown Specify the file paths for the dataset you want to merge with:\n",
        "geno1_path = \"/content/aadr_v62.0_HO_public.geno\"  # @param {type:\"string\"}\n",
        "snp1_path = \"/content/aadr_v62.0_HO_public.snp\"  # @param {type:\"string\"}\n",
        "ind1_path = \"/content/aadr_v62.0_HO_public.ind\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Number of Threads for Mergeit**:\n",
        "num_threads = 2  # @param {type:\"integer\"}\n",
        "\n",
        "# Ensure required inputs are valid\n",
        "if not genome_filepath:\n",
        "    raise ValueError(\"Please specify the filepath to your 23andMe TXT file.\")\n",
        "if not output_base:\n",
        "    raise ValueError(\"Please specify an output base name.\")\n",
        "if not geno1_path or not snp1_path or not ind1_path:\n",
        "    raise ValueError(\"Please specify the file paths for the dataset to merge with.\")\n",
        "\n",
        "# Define paths dynamically based on user inputs\n",
        "fam_file_path = f\"/content/{output_base}.fam\"\n",
        "plink_file_prefix = f\"/content/{output_base}\"\n",
        "if trim_with_snplist:\n",
        "    output_base_trimmed = f\"{output_base}trimmed\"\n",
        "    plink_file_prefix = f\"/content/{output_base_trimmed}\"\n",
        "\n",
        "# Paths for EIGENSTRAT conversion\n",
        "bedfilepath = f\"/content/{output_base_trimmed}.bed\" if trim_with_snplist else f\"/content/{output_base}.bed\"\n",
        "bimfilepath = f\"/content/{output_base_trimmed}.bim\" if trim_with_snplist else f\"/content/{output_base}.bim\"\n",
        "famfilepath = f\"/content/{output_base_trimmed}.fam\" if trim_with_snplist else f\"/content/{output_base}.fam\"\n",
        "genotypeoutname = f\"{output_base}_converted.geno\"\n",
        "snpoutname = f\"{output_base}_converted.snp\"\n",
        "indivoutname = f\"{output_base}_converted.ind\"\n",
        "\n",
        "# Paths for merging datasets\n",
        "geno2_path = genotypeoutname\n",
        "snp2_path = snpoutname\n",
        "ind2_path = indivoutname\n",
        "output_geno_path = f\"{output_base}_merged.geno\"\n",
        "output_snp_path = f\"{output_base}_merged.snp\"\n",
        "output_ind_path = f\"{output_base}_merged.ind\"\n",
        "\n",
        "# Step 2: Add Swap Memory to Prevent Out-of-Memory Issues\n",
        "print(\"Creating swap memory...\")\n",
        "swap_file_path = \"/swapfile\"\n",
        "os.system(f\"fallocate -l 8G {swap_file_path}\")\n",
        "os.system(f\"chmod 600 {swap_file_path}\")\n",
        "os.system(f\"mkswap {swap_file_path}\")\n",
        "os.system(f\"swapon {swap_file_path}\")\n",
        "print(\"Swap memory created successfully.\")\n",
        "\n",
        "# Step 3: Add AdmixTools to PATH\n",
        "print(\"Adding AdmixTools to PATH...\")\n",
        "os.environ['PATH'] += os.pathsep + \"/content/AdmixTools/bin\"\n",
        "!which qpfstats\n",
        "\n",
        "# Step 4: Convert Genome File with PLINK\n",
        "print(\"Running PLINK conversion...\")\n",
        "!{os.path.join('/content', 'plink')} --23file {genome_filepath} --list-23-indels --allow-no-sex --make-bed --out {output_base}\n",
        "\n",
        "# Step 5: Update the .fam File\n",
        "print(\"Updating .fam file...\")\n",
        "new_fam_line = f\"{family_id} {individual_id} {father_id} {mother_id} {sex_code} {phenotype_value}\\n\"\n",
        "with open(fam_file_path, 'w') as fam_file:\n",
        "    fam_file.write(new_fam_line)\n",
        "print(f\".fam file updated successfully: {fam_file_path}\")\n",
        "\n",
        "# Step 6: Trim PLINK File Using SNP List (if selected)\n",
        "if trim_with_snplist:\n",
        "    if not os.path.isfile(snplist_path):\n",
        "        raise ValueError(f\"Selected SNP list file '{snplist_path}' does not exist.\")\n",
        "    print(\"Trimming PLINK file...\")\n",
        "    trim_command = f\"/content/plink --bfile {output_base} --extract {snplist_path} --make-bed --allow-no-sex --out {output_base_trimmed}\"\n",
        "    subprocess.run(trim_command, shell=True, check=True)\n",
        "    print(f\"Trimmed PLINK file created: {output_base_trimmed}\")\n",
        "\n",
        "# Step 7: Create Parameter File for EIGENSTRAT Conversion\n",
        "print(\"Creating convertf parameter file...\")\n",
        "convertf_param_content = f\"\"\"\n",
        "genotypename: {bedfilepath}\n",
        "snpname: {bimfilepath}\n",
        "indivname: {famfilepath}\n",
        "genotypeoutname: {genotypeoutname}\n",
        "snpoutname: {snpoutname}\n",
        "indivoutname: {indivoutname}\n",
        "prodercheck: YES\n",
        "\"\"\"\n",
        "with open(\"/content/convertf_param.par\", \"w\") as param_file:\n",
        "    param_file.write(convertf_param_content)\n",
        "print(\"convertf parameter file created successfully.\")\n",
        "\n",
        "# Step 8: Convert PLINK to PACKEDANCESTRYMAP\n",
        "print(\"Running convertf...\")\n",
        "!convertf -p /content/convertf_param.par\n",
        "\n",
        "# Step 9: Create Parameter File for Dataset Merging\n",
        "print(\"Creating mergeit parameter file...\")\n",
        "mergeit_param_content = f\"\"\"\n",
        "geno1: {geno1_path}\n",
        "snp1: {snp1_path}\n",
        "ind1: {ind1_path}\n",
        "geno2: {geno2_path}\n",
        "snp2: {snp2_path}\n",
        "ind2: {ind2_path}\n",
        "genooutfilename: {output_geno_path}\n",
        "snpoutfilename: {output_snp_path}\n",
        "indoutfilename: {output_ind_path}\n",
        "testmismatch: NO\n",
        "numthreads: {num_threads}\n",
        "\"\"\"\n",
        "with open(\"/content/mergeit_param.par\", \"w\") as merge_param_file:\n",
        "    merge_param_file.write(mergeit_param_content)\n",
        "print(\"mergeit parameter file created successfully.\")\n",
        "\n",
        "# Step 10: Run mergeit\n",
        "print(\"Merging datasets...\")\n",
        "!mergeit -p /content/mergeit_param.par\n",
        "\n",
        "# Step 11: Verify Merging Results\n",
        "print(\"Verifying merged files...\")\n",
        "merged_files_exist = all(os.path.exists(file) for file in [output_geno_path, output_snp_path, output_ind_path])\n",
        "if merged_files_exist:\n",
        "    print(\"Merging completed successfully.\")\n",
        "else:\n",
        "    print(\"An error occurred during merging.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGzig6132SSB"
      },
      "source": [
        "**While the previous step is running, I urge you to use the File Explorer and double-click on the AADR .xlsx file. The 1st column is the family+individual ID. The 2nd column is the sex (M, F, unspecified). The 3rd column is the sample label: Scroll through the labels and start to form a list of right populations and left populations (samples you think you are admixed with). The number of left/source populations must be less than or equal to the number of right/reference. Read through [this](https://pmc.ncbi.nlm.nih.gov/articles/PMC8049561/) paper to obtain insight into the theory.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZG9UI3J36rd"
      },
      "source": [
        "# **[5] AT2 qpAdm Prep and Running**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIYz130a4C1I"
      },
      "source": [
        "**You should now have a dataset with your data merged in. Use the File Explorer and double-click the .ind file. It should open on the right and your sample will be ALL the way at the bottom with ??? in the 3rd label. Manually rename yourself with your desired label and remove spaces such that there is only one space between your sex and label.**\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **qpAdm Parameters (ADMIXTOOLS2)**\n",
        "This guide explains the parameters used in `qpAdm`, along with their **default values** and **descriptions**.\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÇ Dataset & Populations**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `prefix` | `/content/dataset` | Prefix for genotype files (`.ind`, `.snp`, `.geno`). |\n",
        "| `left_poplist` | `\"Example.AG,...\"` | Comma-separated list of **source (left) populations**. |\n",
        "| `right_poplist` | `\"Mbuti.DG,...\"` | Comma-separated list of **outgroup (right) populations**. |\n",
        "| `target` | `\"Target.DG\"` | The **target population** being modeled. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÑ Output Files**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `weights_file` | `\"weights1.csv\"` | File to store **admixture weight results**. |\n",
        "| `popdrop_file` | `\"popdrop1.csv\"` | File to store **population drop results**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **‚öôÔ∏è qpAdm Model Parameters**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `allsnps` | `True` | If `True`, each f4-statistic uses **all available SNPs** instead of the full intersection across populations. |\n",
        "| `fudge` | `1e-04` | A **small constant** added to the covariance matrix diagonal before inversion to stabilize calculations. |\n",
        "| `fudge_twice` | `False` | If `True`, applies `fudge` a second time to **match qpAdm‚Äôs original implementation**. |\n",
        "| `boot` | `False` | If `True`, enables **bootstrap resampling** for standard errors. Default is **jackknife resampling**. |\n",
        "| `getcov` | `True` | If `False`, skips covariance matrix calculation (for faster runs). |\n",
        "| `constrained` | `False` | If `True`, constrains admixture proportions to be **non-negative** (0 to 1). |\n",
        "| `return_f4` | `False` | If `True`, returns **f4-statistics** in addition to admixture weights. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üîß Computational Options**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `cpp` | `True` | If `True`, uses **C++ optimizations** for faster execution. If `False`, runs in **pure R** (useful for debugging). |\n",
        "| `verbose` | `True` | If `True`, prints **detailed status updates** during execution. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üîå UI & Debugging**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `detach_shinyjs` | `True` | Ensures `shinyjs` is detached to **prevent UI conflicts in R-based interfaces**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Notes**\n",
        "- **Required Parameters**: `prefix`, `left_poplist`, `right_poplist`, `target`\n",
        "- **Performance Tweaks**:\n",
        "  - Use `allsnps = True` if working with **sparse datasets**.\n",
        "  - Set `cpp = False` if debugging **computation errors**.\n",
        "  - Use `getcov = False` for **faster runs** with large datasets.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xVF7fvsTbguT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "D1KBgV5EdcXu"
      },
      "outputs": [],
      "source": [
        "# Dataset prefix\n",
        "prefix = \"/content/aadr_v62.0_HO_public\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations (can be comma-separated string or quoted list)\n",
        "left_poplist = \"IBS.DG, Nahua.DG, Kongo.DG\"  # @param {type:\"string\"}\n",
        "right_poplist = \"Mbuti.DG, Russia_UstIshim_IUP.DG, Russia_Kostenki14_UP.SG, Switzerland_Bichon_Epipaleolithic.SG, Turkey_Central_Pinarbasi_Epipaleolithic.AG, Russia_YuzhniyOleniyOstrov_Mesolithic.SG, Georgia_Kotias_Mesolithic.SG, Israel_Natufian.AG, Morocco_Iberomaurusian.AG, China_AmurRiver_Paleolithic.AG, Peru_Lauricocha_8600BP.AG, Spanish.DG, Piapoco.DG, BantuSA.DG\"  # @param {type:\"string\"}\n",
        "target = 'MXL.DG'  # @param {type:\"string\"}\n",
        "\n",
        "# File names for outputs\n",
        "weights_file = \"weights1.csv\"  # @param {type:\"string\"}\n",
        "popdrop_file = \"popdrop1.csv\"  # @param {type:\"string\"}\n",
        "\n",
        "# Additional qpAdm options\n",
        "detach_shinyjs = True  # @param {type:\"boolean\"}\n",
        "allsnps = True  # @param {type:\"boolean\"}\n",
        "fudge = 1e-04  # @param {type:\"number\"}\n",
        "fudge_twice = False  # @param {type:\"boolean\"}\n",
        "boot = False  # @param {type:\"boolean\"}\n",
        "getcov = True  # @param {type:\"boolean\"}\n",
        "constrained = False  # @param {type:\"boolean\"}\n",
        "return_f4 = False  # @param {type:\"boolean\"}\n",
        "cpp = True  # @param {type:\"boolean\"}\n",
        "verbose = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse population lists\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        return [pop.strip().strip(\"'\") for pop in poplist.split(',')]\n",
        "    return poplist\n",
        "\n",
        "# Parse the population lists\n",
        "left = parse_poplist(left_poplist)\n",
        "right = parse_poplist(right_poplist)\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['left'] = robjects.StrVector(left)\n",
        "robjects.globalenv['right'] = robjects.StrVector(right)\n",
        "robjects.globalenv['target'] = target\n",
        "robjects.globalenv['weights_file'] = weights_file\n",
        "robjects.globalenv['popdrop_file'] = popdrop_file\n",
        "robjects.globalenv['detach_shinyjs'] = detach_shinyjs\n",
        "robjects.globalenv['allsnps'] = allsnps\n",
        "robjects.globalenv['fudge'] = fudge\n",
        "robjects.globalenv['fudge_twice'] = fudge_twice\n",
        "robjects.globalenv['boot'] = boot\n",
        "robjects.globalenv['getcov'] = getcov\n",
        "robjects.globalenv['constrained'] = constrained\n",
        "robjects.globalenv['return_f4'] = return_f4\n",
        "robjects.globalenv['cpp'] = cpp\n",
        "robjects.globalenv['verbose'] = verbose\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l0KnHxSvdrlg"
      },
      "outputs": [],
      "source": [
        "#@markdown **Run qpAdm (AT2)**\n",
        "\n",
        "%%R\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "\n",
        "# Retrieve parameters from Python\n",
        "prefix <- get(\"prefix\", envir = .GlobalEnv)\n",
        "left <- get(\"left\", envir = .GlobalEnv)\n",
        "right <- get(\"right\", envir = .GlobalEnv)\n",
        "target <- get(\"target\", envir = .GlobalEnv)\n",
        "weights_file <- get(\"weights_file\", envir = .GlobalEnv)\n",
        "popdrop_file <- get(\"popdrop_file\", envir = .GlobalEnv)\n",
        "detach_shinyjs <- get(\"detach_shinyjs\", envir = .GlobalEnv)\n",
        "allsnps <- get(\"allsnps\", envir = .GlobalEnv)\n",
        "fudge <- get(\"fudge\", envir = .GlobalEnv)\n",
        "fudge_twice <- get(\"fudge_twice\", envir = .GlobalEnv)\n",
        "boot <- get(\"boot\", envir = .GlobalEnv)\n",
        "getcov <- get(\"getcov\", envir = .GlobalEnv)\n",
        "constrained <- get(\"constrained\", envir = .GlobalEnv)\n",
        "return_f4 <- get(\"return_f4\", envir = .GlobalEnv)\n",
        "cpp <- get(\"cpp\", envir = .GlobalEnv)\n",
        "verbose <- get(\"verbose\", envir = .GlobalEnv)\n",
        "\n",
        "# Detach shinyjs if specified\n",
        "if (detach_shinyjs) {\n",
        "  try(detach(\"package:shinyjs\", unload=TRUE), silent=TRUE)\n",
        "}\n",
        "\n",
        "# Print parameters for verification\n",
        "print(paste(\"Prefix path: \", prefix))\n",
        "print(paste(\"Left populations: \", toString(left)))\n",
        "print(paste(\"Right populations: \", toString(right)))\n",
        "print(paste(\"Target population: \", target))\n",
        "print(paste(\"Weights file: \", weights_file))\n",
        "print(paste(\"Popdrop file: \", popdrop_file))\n",
        "print(paste(\"Detach shinyjs: \", detach_shinyjs))\n",
        "print(paste(\"All SNPs: \", allsnps))\n",
        "print(paste(\"Fudge factor: \", fudge))\n",
        "print(paste(\"Fudge twice: \", fudge_twice))\n",
        "print(paste(\"Bootstrap resampling: \", boot))\n",
        "print(paste(\"Compute covariance: \", getcov))\n",
        "print(paste(\"Constrain weights: \", constrained))\n",
        "print(paste(\"Return f4 statistics: \", return_f4))\n",
        "print(paste(\"Use C++ functions: \", cpp))\n",
        "print(paste(\"Verbose mode: \", verbose))\n",
        "\n",
        "# Execute qpAdm analysis\n",
        "results <- qpadm(prefix,\n",
        "                 left,\n",
        "                 right,\n",
        "                 target,\n",
        "                 allsnps = allsnps,\n",
        "                 fudge = fudge,\n",
        "                 fudge_twice = fudge_twice,\n",
        "                 boot = boot,\n",
        "                 getcov = getcov,\n",
        "                 constrained = constrained,\n",
        "                 return_f4 = return_f4,\n",
        "                 cpp = cpp,\n",
        "                 verbose = verbose)\n",
        "\n",
        "# Set output options\n",
        "options(dplyr.width = Inf, max.print = 100000, digits = 10)\n",
        "\n",
        "# Save results\n",
        "write.csv(results$weights, weights_file, row.names = FALSE)\n",
        "write.csv(results$popdrop, popdrop_file, row.names = FALSE)\n",
        "\n",
        "# Print results\n",
        "print(results$weights, n = Inf)\n",
        "print(results$popdrop, n = Inf)\n",
        "\n",
        "if (\"f4\" %in% names(results)) {\n",
        "  print(results$f4, n = Inf)\n",
        "}\n",
        "\n",
        "print(\"qpAdm analysis complete. Results are also saved in CSV files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import textwrap\n",
        "import numpy as np\n",
        "\n",
        "# @title **Parse and Visualize qpAdm (AT2) Output**\n",
        "# @markdown Please paste the paths to your qpAdm weights and popdrop files:\n",
        "weights_file = \"/content/weights1.csv\"  # @param {type:\"string\"}\n",
        "popdrop_file = \"/content/popdrop1.csv\"  # @param {type:\"string\"}\n",
        "\n",
        "def parse_qpadm_at2(weights_file, popdrop_file):\n",
        "    try:\n",
        "        # Load the weights file (admixture proportions)\n",
        "        df_weights = pd.read_csv(weights_file)\n",
        "\n",
        "        if not {'target', 'left', 'weight', 'se'}.issubset(df_weights.columns):\n",
        "            raise ValueError(\"Missing required columns in the weights file.\")\n",
        "\n",
        "        target_population = df_weights[\"target\"].iloc[0]\n",
        "\n",
        "        # Convert proportions to percentages\n",
        "        df_weights[\"Admixture Proportion\"] = df_weights[\"weight\"] * 100\n",
        "        df_weights[\"Standard Error\"] = df_weights[\"se\"] * 100\n",
        "\n",
        "        # Handle case where qpAdm reports 0.0 proportions\n",
        "        if df_weights[\"Admixture Proportion\"].sum() == 0 and len(df_weights) == 1:\n",
        "            df_weights[\"Admixture Proportion\"] = 100.0\n",
        "            df_weights[\"Standard Error\"] = 0.0\n",
        "\n",
        "        # Load the popdrop file (chi-squared & p-value)\n",
        "        df_popdrop = pd.read_csv(popdrop_file)\n",
        "\n",
        "        if not {'chisq', 'p'}.issubset(df_popdrop.columns):\n",
        "            raise ValueError(\"Missing required columns in the popdrop file.\")\n",
        "\n",
        "        chi_squared = df_popdrop[\"chisq\"].iloc[0] if not df_popdrop.empty else 0.0\n",
        "        p_value = df_popdrop[\"p\"].iloc[0] if not df_popdrop.empty else 1.0\n",
        "\n",
        "        return df_weights, target_population, chi_squared, p_value\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing qpAdm (AT2) output: {e}\")\n",
        "        return pd.DataFrame(), '', 0.0, 1.0\n",
        "\n",
        "# Parse the results\n",
        "df_admixture, target_population, chi_squared, p_value = parse_qpadm_at2(weights_file, popdrop_file)\n",
        "\n",
        "if not df_admixture.empty:\n",
        "    print(df_admixture)\n",
        "else:\n",
        "    print(\"Parsed DataFrame is empty or an error was encountered.\")\n",
        "\n",
        "# @title Select Plot Type\n",
        "# @markdown Choose the type of plot to display:\n",
        "plot_type = \"Pie Chart\"  # @param [\"Bar Graph\", \"Pie Chart\"]\n",
        "\n",
        "def wrap_text(text, width=50):\n",
        "    wrapped_lines = textwrap.wrap(text, width)\n",
        "    return \"\\n\".join(wrapped_lines)\n",
        "\n",
        "def create_plot(plot_type):\n",
        "    if not df_admixture.empty:\n",
        "        sns.set(style=\"whitegrid\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
        "\n",
        "        if plot_type == \"Bar Graph\":\n",
        "            palette = sns.color_palette(\"deep\", len(df_admixture))\n",
        "            bars = ax.bar(df_admixture['left'], df_admixture['Admixture Proportion'], color=palette)\n",
        "\n",
        "            for bar, prop, se in zip(bars, df_admixture['Admixture Proportion'], df_admixture['Standard Error']):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.2f}% ¬± {se:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
        "\n",
        "            ax.set_title(f'ADMIXTOOLS2 | Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {chi_squared:.2f}, P-Value: {p_value:.12g})', fontsize=9, fontweight='bold')\n",
        "            ax.set_xlabel('Source Population', fontsize=10, fontweight='bold')\n",
        "            ax.set_ylabel('Admixture Proportion (%)', fontsize=10, fontweight='bold')\n",
        "            ax.tick_params(axis='x', rotation=45, labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "            ax.tick_params(axis='y', labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "\n",
        "            for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "                label.set_fontweight('bold')\n",
        "\n",
        "            ax.spines['top'].set_linewidth(1.5)\n",
        "            ax.spines['right'].set_linewidth(1.5)\n",
        "            ax.spines['bottom'].set_linewidth(1.5)\n",
        "            ax.spines['left'].set_linewidth(1.5)\n",
        "\n",
        "            # Watermark\n",
        "            plt.figtext(0.98, 0.02, \"github.com/agonist11/colabadmixtools\", fontsize=7, color=\"gray\", ha=\"right\", va=\"bottom\", alpha=0.5)\n",
        "\n",
        "        elif plot_type == \"Pie Chart\":\n",
        "            if np.any(df_admixture['Admixture Proportion'] <= 0):\n",
        "                print(\"Admixture proportions must be positive for pie charts.\")\n",
        "                return\n",
        "\n",
        "            wedges, texts = ax.pie(\n",
        "                df_admixture['Admixture Proportion'],\n",
        "                colors=sns.color_palette(\"deep\", len(df_admixture)),\n",
        "                startangle=140,\n",
        "                wedgeprops=dict(edgecolor='black', width=0.3)\n",
        "            )\n",
        "\n",
        "            # Remove pie chart labels\n",
        "            for text in texts:\n",
        "                text.set_text('')\n",
        "\n",
        "            ax.legend(wedges, [f'{pop}: {prop:.2f}% ¬± {se:.2f}%' for pop, prop, se in zip(df_admixture['left'], df_admixture['Admixture Proportion'], df_admixture['Standard Error'])], title=\"Admixture Proportions\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=10, title_fontsize='12')\n",
        "\n",
        "            plt.figtext(0.625, 0.97, f'ADMIXTOOLS2 | Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {chi_squared:.2f}, P-Value: {p_value:.12g})', ha='center', va='top', fontsize=10, fontweight='bold')\n",
        "\n",
        "            # Watermark\n",
        "            plt.figtext(0.98, 0.02, \"github.com/agonist11/colabadmixtools\", fontsize=7, color=\"gray\", ha=\"right\", va=\"bottom\", alpha=0.5)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No data available for plotting.\")\n",
        "\n",
        "# Create the plot\n",
        "create_plot(plot_type)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qRdoeA1Q6Oc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sneaiW05ffme"
      },
      "source": [
        "# **[6] AT1 qpAdm Prep and Running**\n",
        "**Now we can cross-validate an AT2 model with AT1. Fill in all of the information below. Then run the code cell.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJqFuBimePGE"
      },
      "source": [
        "## **qpAdm Parameters Explained**\n",
        "Below is a list of parameters used in `qpAdm`, along with their default values and explanations.\n",
        "\n",
        "### **üìå Main Input Parameters**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `instem` | Required | Prefix for input files (`.ind`, `.snp`, `.geno`). Example: `Florio_mergedHO` will look for `Florio_mergedHO.ind`, etc. |\n",
        "| `popleft` | `left1.txt` | File containing the **target** and **source** populations (one per line). |\n",
        "| `popright` | `right1.txt` | File containing the **outgroup (right)** populations (one per line). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå General Analysis Settings**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `details` | `YES` | Provides additional output about model fit. |\n",
        "| `allsnps` | `NO` | If `YES`, uses all available SNPs for each f4-statistic instead of requiring full intersection. |\n",
        "| `summary` | `YES` | Prints a summary line with p-values and admixture proportions. |\n",
        "| `inbreed` | `NO` | If `YES`, accounts for inbreeding in source populations. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Optional SNP and Jackknife Settings**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `badsnpname` | `NULL` | File containing SNPs to **ignore** during analysis (one per line). |\n",
        "| `blockname` | `NULL` | File defining **custom block numbers** for the block-jackknife method. |\n",
        "| `blgsize` | `0.05` | Jackknife block size in **Morgans**. qpAdm auto-corrects if mistakenly set in centimorgans. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Chromosome-Specific Options**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `chrom` | `NULL` | Restricts analysis to a **specific chromosome**. Example: `chrom: \"1\"` analyzes only **Chromosome 1**. |\n",
        "| `nochrom` | `NULL` | Excludes a specific chromosome from analysis (useful for jackknife corrections). |\n",
        "| `numchrom` | `22` | Defines **total chromosomes used** (default is **22 autosomes** for humans). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Model Robustness and Precision**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `hiprec_covar` | `NO` | If `YES`, prints **high-precision error covariance matrix** (1 billion multiplier instead of 1 million). |\n",
        "| `diagplus` | `NULL` | Adjusts diagonal regularization for **robust results** in difficult models. `0` disables. |\n",
        "| `hires` | `NO` | If `YES`, increases decimal places for **admixture proportions** (from 3 to 9 decimal places). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Genetic Distance Handling**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `gfromp` | `NO` | If `YES`, ignores **genetic distance** from `.snp` file and assumes **100Mb ‚âà 1 Morgan**. |\n",
        "| `fancyf4` | `YES` | Allows computing f4-statistics even if **one population is missing**, as long as `A = B`. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Randomization & Reproducibility**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `seed` | `0` | Sets a **random seed** for reproducibility (`0` = system clock-based randomization). |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Notes**\n",
        "- Parameters marked as `NULL` are **optional** and left as \"\" and will be omitted if left empty.\n",
        "- **Required Parameters**: `instem`, `popleft`, `popright`\n",
        "- **SNP handling & precision settings** help refine **robustness** in complex models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gq3ifm7T_xxA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "#@markdown ## **Set Parameters for qpAdm Analysis and Click to Run**\n",
        "target_population = \"MXL.DG\"  #@param {type:\"string\"}\n",
        "source_populations = \"IBS.DG, Nahua.DG, Kongo.DG\"  #@param {type:\"string\"}\n",
        "reference_populations = \"Mbuti.DG, Russia_UstIshim_IUP.DG, Russia_Kostenki14_UP.SG, Switzerland_Bichon_Epipaleolithic.SG, Turkey_Central_Pinarbasi_Epipaleolithic.AG, Russia_YuzhniyOleniyOstrov_Mesolithic.SG, Georgia_Kotias_Mesolithic.SG, Israel_Natufian.AG, Morocco_Iberomaurusian.AG, China_AmurRiver_Paleolithic.AG, Peru_Lauricocha_8600BP.AG, Spanish.DG, Piapoco.DG, BantuSA.DG\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the **prefix (instem)** for the dataset files:\n",
        "instem = \"aadr_v62.0_HO_public\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Select **YES or NO** for allsnps:\n",
        "allsnps = \"YES\"  #@param [\"YES\", \"NO\"]\n",
        "\n",
        "#@markdown Select **YES or NO** for inbreed:\n",
        "inbreed = \"NO\"  #@param [\"YES\", \"NO\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Additional qpAdm Parameters**\n",
        "details = \"YES\"  #@param [\"YES\", \"NO\"]\n",
        "hiprec_covar = \"NO\"  #@param [\"YES\", \"NO\"]\n",
        "badsnpname = \"\"  #@param {type:\"string\"}\n",
        "blockname = \"\"  #@param {type:\"string\"}\n",
        "blgsize = 0.05  #@param {type:\"number\"}\n",
        "gfromp = \"NO\"  #@param [\"YES\", \"NO\"]\n",
        "fancyf4 = \"YES\"  #@param [\"YES\", \"NO\"]\n",
        "seed = 0  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Chromosome-Specific Parameters**\n",
        "chrom = \"\"  #@param {type:\"string\"}  # Restricts analysis to this chromosome (default: all)\n",
        "nochrom = \"\"  #@param {type:\"string\"}  # Excludes this chromosome from analysis\n",
        "numchrom = 22  #@param {type:\"integer\"}  # Total number of chromosomes (default: 22)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Matrix and Precision Adjustments**\n",
        "diagplus = \"\"  #@param {type:\"string\"}  # Robustness adjustment (default: NULL)\n",
        "hires = \"NO\"  #@param [\"YES\", \"NO\"]  # Increases decimal places (default: NO)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Enter desired output filename (without `.txt` extension):**\n",
        "output_filename = \"results3\"  #@param {type:\"string\"}\n",
        "\n",
        "# Step 1: Prepare Population Files\n",
        "def prepare_qpAdm_files():\n",
        "    source_list = source_populations.split(\",\")\n",
        "    reference_list = reference_populations.split(\",\")\n",
        "\n",
        "    with open(\"left1.txt\", \"w\") as file:\n",
        "        file.write(f\"{target_population}\\n\" + \"\\n\".join(source_list))\n",
        "\n",
        "    with open(\"right1.txt\", \"w\") as file:\n",
        "        file.write(\"\\n\".join(reference_list))\n",
        "\n",
        "    with open(\"poplist\", \"w\") as file:\n",
        "        file.write(\"\\n\".join(reference_list) + f\"\\n{target_population}\\n\" + \"\\n\".join(source_list))\n",
        "\n",
        "    print(\"‚úÖ Left, Right, and Poplist files created successfully!\")\n",
        "\n",
        "# Step 2: Create the parqpAdm Parameter File\n",
        "def create_parqpAdm_file():\n",
        "    parqpAdm_content = f\"\"\"\n",
        "instem:         {instem}\n",
        "indivname:      {instem}.ind\n",
        "snpname:        {instem}.snp\n",
        "genotypename:   {instem}.geno\n",
        "popleft:        left1.txt\n",
        "popright:       right1.txt\n",
        "details:        {details}\n",
        "allsnps:        {allsnps}\n",
        "inbreed:        {inbreed}\n",
        "summary:        YES\n",
        "hiprec_covar:   {hiprec_covar}\n",
        "blgsize:        {blgsize}\n",
        "gfromp:         {gfromp}\n",
        "fancyf4:        {fancyf4}\n",
        "seed:           {seed}\n",
        "numchrom:       {numchrom}\n",
        "hires:          {hires}\n",
        "\"\"\"\n",
        "\n",
        "    # Only include optional parameters if set\n",
        "    if badsnpname.strip():\n",
        "        parqpAdm_content += f\"badsnpname:     {badsnpname}\\n\"\n",
        "    if blockname.strip():\n",
        "        parqpAdm_content += f\"blockname:      {blockname}\\n\"\n",
        "    if chrom.strip():\n",
        "        parqpAdm_content += f\"chrom:          {chrom}\\n\"\n",
        "    if nochrom.strip():\n",
        "        parqpAdm_content += f\"nochrom:        {nochrom}\\n\"\n",
        "    if diagplus.strip():\n",
        "        parqpAdm_content += f\"diagplus:       {diagplus}\\n\"\n",
        "\n",
        "    with open(\"/content/parqpAdm.txt\", \"w\") as file:\n",
        "        file.write(parqpAdm_content)\n",
        "\n",
        "    print(\"‚úÖ Parameter file for qpAdm created successfully!\")\n",
        "\n",
        "# Step 3: Add AdmixTools to Path\n",
        "def add_admixtools_path():\n",
        "    os.environ['PATH'] += os.pathsep + \"/content/AdmixTools/bin\"\n",
        "    print(\"‚úÖ AdmixTools added to PATH.\")\n",
        "\n",
        "# Step 4: Run qpAdm Analysis\n",
        "def run_qpAdm():\n",
        "    ! /content/AdmixTools/bin/qpAdm -p /content/parqpAdm.txt > /content/{output_filename}.txt\n",
        "    print(f\"‚úÖ qpAdm analysis completed! Results saved to {output_filename}.txt\")\n",
        "\n",
        "# Run All Steps Sequentially with 2-Second Delay\n",
        "prepare_qpAdm_files()\n",
        "time.sleep(2)\n",
        "create_parqpAdm_file()\n",
        "time.sleep(2)\n",
        "add_admixtools_path()\n",
        "time.sleep(2)\n",
        "run_qpAdm()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZx-bsMS53kz"
      },
      "source": [
        "**After running the previous code cell, your results should be in the File Explorer on the left. Double-click to open them or right-click to Download. AT1 runs take longer, try AT2 (step above) or Utility 6 (below) for quicker model optimization.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F07l5ivu6E4L"
      },
      "source": [
        "# **[6b] Data Analysis and Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p_bh7zix6MUf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import textwrap\n",
        "import numpy as np\n",
        "\n",
        "# @title Parse and Visualize qpAdm Output\n",
        "# @markdown Please paste the path to your qpAdm result file:\n",
        "qpadm_results_path = \"/content/results3.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "def parse_qpadm_output(filepath):\n",
        "    try:\n",
        "        with open(filepath) as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract target population\n",
        "        target_population = content.split('left pops:\\n')[1].split('\\n')[0].strip().rsplit(maxsplit=1)[0]\n",
        "\n",
        "        # Extract left populations\n",
        "        left_pops_raw = content.split('left pops:\\n')[1].split('\\n\\n')[0].strip().split('\\n')[1:]  # Skip target population\n",
        "        left_pops = [pop.rsplit(maxsplit=1)[0] for pop in left_pops_raw]\n",
        "\n",
        "        # Extract right populations\n",
        "        right_pops_raw = content.split('right pops:\\n')[1].split('\\n\\n')[0].strip().split('\\n')\n",
        "        right_pops = [pop.rsplit(maxsplit=1)[0] for pop in right_pops_raw]\n",
        "\n",
        "        # Extract best coefficients and standard errors\n",
        "        try:\n",
        "            best_coeffs_section = content.split('best coefficients:')[1].split('\\n')[0].strip().split()\n",
        "            best_coeffs = [float(bc) * 100 for bc in best_coeffs_section] if best_coeffs_section else [100.0]\n",
        "        except (IndexError, ValueError):\n",
        "            best_coeffs = [100.0]  # Default to 100% if parsing fails\n",
        "\n",
        "        try:\n",
        "            std_errors_raw = content.split('std. errors:')[1].split('\\n')[0].strip().split()\n",
        "            std_errors = [float(se) * 100 for se in std_errors_raw] if std_errors_raw else [0.0]\n",
        "        except (IndexError, ValueError):\n",
        "            std_errors = [0.0]  # Default error to 0.0\n",
        "\n",
        "        # Extract chi-squared value\n",
        "        try:\n",
        "            chi_squared = float(content.split('chisq:')[1].split()[0])\n",
        "        except (IndexError, ValueError):\n",
        "            chi_squared = 0.0\n",
        "\n",
        "        # Extract p-value\n",
        "        try:\n",
        "            p_value_line = content.split('tail:')[1].split()[0]\n",
        "            p_value = float(p_value_line.strip())\n",
        "        except (IndexError, ValueError):\n",
        "            p_value = 1.0  # Default to a valid p-value\n",
        "\n",
        "        # Ensure at least one coefficient is non-zero\n",
        "        if sum(best_coeffs) == 0 and len(left_pops) == 1:\n",
        "            best_coeffs = [100.0]  # If single-source model, default to 100%\n",
        "\n",
        "        # Construct DataFrame\n",
        "        df = pd.DataFrame({\n",
        "            'Source Population': left_pops,\n",
        "            'Admixture Proportion': best_coeffs,\n",
        "            'Standard Error': std_errors,\n",
        "            'Chi-Squared': [chi_squared] * len(left_pops),\n",
        "            'P-Value': [p_value] * len(left_pops)\n",
        "        })\n",
        "\n",
        "        return df, target_population, right_pops\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing the qpAdm output: {e}\")\n",
        "        return pd.DataFrame(), '', []\n",
        "\n",
        "# Parse the results and check if the DataFrame is not empty\n",
        "df_admixture, target_population, right_pops = parse_qpadm_output(qpadm_results_path)\n",
        "\n",
        "if not df_admixture.empty:\n",
        "    print(df_admixture)\n",
        "    print(\"\\nReference Populations Used:\")\n",
        "    for pop in right_pops:\n",
        "        print(pop)\n",
        "else:\n",
        "    print(\"Parsed DataFrame is empty or an error was encountered.\")\n",
        "\n",
        "# @title Select Plot Type\n",
        "# @markdown Choose the type of plot to display:\n",
        "plot_type = \"Pie Chart\"  # @param [\"Bar Graph\", \"Pie Chart\"]\n",
        "\n",
        "def wrap_text(text, width=50):\n",
        "    wrapped_lines = textwrap.wrap(text, width)\n",
        "    return \"\\n\".join(wrapped_lines)\n",
        "\n",
        "def create_plot(plot_type):\n",
        "    if not df_admixture.empty:\n",
        "        sns.set(style=\"whitegrid\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
        "\n",
        "        if plot_type == \"Bar Graph\":\n",
        "            palette = sns.color_palette(\"deep\", len(df_admixture))\n",
        "            bars = ax.bar(df_admixture['Source Population'], df_admixture['Admixture Proportion'], color=palette)\n",
        "\n",
        "            for bar, prop, se in zip(bars, df_admixture['Admixture Proportion'], df_admixture['Standard Error']):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.2f}% ¬± {se:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
        "\n",
        "            ax.set_title(f'ADMIXTOOLS1 | Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {df_admixture[\"Chi-Squared\"].iloc[0]:.2f}, P-Value: {df_admixture[\"P-Value\"].iloc[0]:.12g})', fontsize=9, fontweight='bold')\n",
        "            ax.set_xlabel('Source Population', fontsize=10, fontweight='bold')\n",
        "            ax.set_ylabel('Admixture Proportion (%)', fontsize=10, fontweight='bold')\n",
        "            ax.tick_params(axis='x', rotation=45, labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "            ax.tick_params(axis='y', labelsize=10, labelcolor='black', width=1.5, length=6, direction='out')\n",
        "\n",
        "            for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "                label.set_fontweight('bold')\n",
        "\n",
        "            ax.spines['top'].set_linewidth(1.5)\n",
        "            ax.spines['right'].set_linewidth(1.5)\n",
        "            ax.spines['bottom'].set_linewidth(1.5)\n",
        "            ax.spines['left'].set_linewidth(1.5)\n",
        "\n",
        "            # Watermark\n",
        "            plt.figtext(0.98, 0.02, \"github.com/agonist11/colabadmixtools\", fontsize=7, color=\"gray\", ha=\"right\", va=\"bottom\", alpha=0.5)\n",
        "\n",
        "        elif plot_type == \"Pie Chart\":\n",
        "            if np.any(df_admixture['Admixture Proportion'] <= 0):\n",
        "                print(\"Admixture proportions must be positive for pie charts.\")\n",
        "                return\n",
        "\n",
        "            wedges, texts = ax.pie(\n",
        "                df_admixture['Admixture Proportion'],\n",
        "                colors=sns.color_palette(\"deep\", len(df_admixture)),\n",
        "                startangle=140,\n",
        "                wedgeprops=dict(edgecolor='black', width=0.3)\n",
        "            )\n",
        "\n",
        "            # Remove pie chart labels and percentages\n",
        "            for text in texts:\n",
        "                text.set_text('')\n",
        "\n",
        "            ax.legend(wedges, [f'{pop}: {prop:.2f}% ¬± {se:.2f}%' for pop, prop, se in zip(df_admixture['Source Population'], df_admixture['Admixture Proportion'], df_admixture['Standard Error'])], title=\"Admixture Proportions\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=10, title_fontsize='12')\n",
        "\n",
        "            plt.figtext(0.625, 0.97, f'ADMIXTOOLS1 | Target Population: {target_population}\\nAdmixture Proportions (Chi-Squared: {df_admixture[\"Chi-Squared\"].iloc[0]:.2f}, P-Value: {df_admixture[\"P-Value\"].iloc[0]:.12g})', ha='center', va='top', fontsize=10, fontweight='bold')\n",
        "\n",
        "            # Watermark\n",
        "            plt.figtext(0.98, 0.02, \"github.com/agonist11/colabadmixtools\", fontsize=7, color=\"gray\", ha=\"right\", va=\"bottom\", alpha=0.5)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No data available for plotting.\")\n",
        "\n",
        "# Create the plot\n",
        "create_plot(plot_type)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d5U-qtcF0x2"
      },
      "source": [
        "# **[7] Mounting Drive and Saving Compressed Files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FwJ1vsWGEk7"
      },
      "source": [
        "To avoid the lengthy merging process in the future, we can mount our Google Drive and save any intermediate files and results using the code cell below. This will create a folder called **colabadmixtools** for you. Especially the merged dataset files (i.e. the .ind, .geno, .snp files). If you would like to do analysis on your merged data again in the future, just mount your drive using and specify the path of the compressed folder (Step 1 Option 3). After you mount, your drive should be at /content/drive/MyDrive within Colab. You will still need to perform Step 1 in the future but can then skip to Step 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FjmXl43TG3Bx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "from ipywidgets import widgets, VBox\n",
        "from IPython.display import display\n",
        "\n",
        "# @title **Mount Google Drive & Compress Selected Files**\n",
        "# @markdown This script will:\n",
        "# @markdown 1. **List all available .geno, .ind, .snp, .bed, .bim, .fam files**\n",
        "# @markdown 2. **Allow interactive selection of files via checkboxes**\n",
        "# @markdown 3. **Zip selected files & save them in Google Drive (`colabadmixtools` folder)**\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directory for saving ZIP file in Google Drive\n",
        "drive_folder = \"/content/drive/MyDrive/colabadmixtools\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# List files in `/content/`\n",
        "available_files = [f for f in os.listdir(\"/content/\") if f.endswith(('.geno', '.ind', '.snp', '.bed', '.bim', '.fam'))]\n",
        "\n",
        "if not available_files:\n",
        "    print(\"‚ùå No matching files found in /content/. Please upload or generate files first.\")\n",
        "else:\n",
        "    # Display available files with checkboxes\n",
        "    file_checkboxes = [widgets.Checkbox(value=False, description=f) for f in available_files]\n",
        "    files_box = VBox(file_checkboxes)\n",
        "\n",
        "    # Input for ZIP file name\n",
        "    zip_folder_name = widgets.Text(\n",
        "        value=\"compressed_data\",\n",
        "        placeholder=\"Enter ZIP file name\",\n",
        "        description=\"ZIP Name:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    display(files_box, zip_folder_name)\n",
        "\n",
        "    def compress_files(b):\n",
        "        selected_files = [cb.description for cb in file_checkboxes if cb.value]\n",
        "        zip_name = zip_folder_name.value.strip()\n",
        "\n",
        "        if not selected_files:\n",
        "            print(\"‚ùå No files selected. Please choose at least one file.\")\n",
        "            return\n",
        "\n",
        "        if not zip_name:\n",
        "            print(\"‚ùå Please enter a ZIP file name.\")\n",
        "            return\n",
        "\n",
        "        zip_path = os.path.join(drive_folder, f\"{zip_name}.zip\")\n",
        "\n",
        "        # Create ZIP archive\n",
        "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file in selected_files:\n",
        "                file_path = os.path.join(\"/content/\", file)\n",
        "                zipf.write(file_path, os.path.basename(file_path))\n",
        "                print(f\"‚úÖ Added: {file}\")\n",
        "\n",
        "        print(f\"\\nüéâ Files successfully compressed and saved to Google Drive: `{zip_path}`\")\n",
        "\n",
        "    # Create button to trigger compression\n",
        "    compress_button = widgets.Button(description=\"Compress & Save to Drive\")\n",
        "    compress_button.on_click(compress_files)\n",
        "    display(compress_button)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdtmteqehLSG"
      },
      "source": [
        "# **Utilities**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTdgStWAhhh6"
      },
      "source": [
        "### **Utility 1: EIGENSTRAT/PACKEDANCESTRYMAP to PLINK Conversion ( + Extraction)**\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **inpref**: Prefix of the input files.\n",
        "- **outpref**: Desired prefix for the PLINK output files.\n",
        "- **inds**: (Optional) Comma-separated list of individuals to extract. If provided, `pops` should be left empty.\n",
        "- **pops**: (Optional) Comma-separated list of populations to extract. If provided, `inds` should be left empty.\n",
        "- **verbose**: Choose whether to print progress updates.\n",
        "\n",
        "Ensure that you provide either `inds` or `pops`, but not both if extracting. WARNING: Conversion of very large datasets is not possible in the Colab runtime (as of now) - please try converting/extracting the populations (Group Labels/IDs) you deem necessary for further analysis to avoid crashing the runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LNkvVx1GhO29"
      },
      "outputs": [],
      "source": [
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the input files\n",
        "inpref = \"/content/Florio_mergedHO\"  # @param {type:\"string\"}\n",
        "\n",
        "# Prefix of the PLINK output files\n",
        "outpref = \"/content/Test5\"  # @param {type:\"string\"}\n",
        "\n",
        "# Individuals to extract (comma-separated string)\n",
        "inds = \"Florio:Florio,HG01516.DG,S_Nahua-2.DG,B_Mbuti-4.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations to extract (comma-separated string)\n",
        "pops = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Verbose option\n",
        "verbose = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse lists\n",
        "def parse_list(input_list):\n",
        "    if isinstance(input_list, str) and input_list:\n",
        "        # Split by commas and strip whitespace\n",
        "        return [item.strip() for item in input_list.split(',')]\n",
        "    return None\n",
        "\n",
        "# Parse the individuals and populations lists\n",
        "inds_list = parse_list(inds)\n",
        "pops_list = parse_list(pops)\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Activate the automatic conversion of pandas objects to R objects\n",
        "pandas2ri.activate()\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['inpref'] = inpref\n",
        "robjects.globalenv['outpref'] = outpref\n",
        "robjects.globalenv['inds'] = robjects.StrVector(inds_list) if inds_list else robjects.NULL\n",
        "robjects.globalenv['pops'] = robjects.StrVector(pops_list) if pops_list else robjects.NULL\n",
        "robjects.globalenv['verbose'] = verbose\n",
        "\n",
        "# Load necessary libraries and run the conversion\n",
        "robjects.r('''\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "\n",
        "# Retrieve the parameters passed from Python\n",
        "inpref <- get(\"inpref\", envir = .GlobalEnv)\n",
        "outpref <- get(\"outpref\", envir = .GlobalEnv)\n",
        "inds <- get(\"inds\", envir = .GlobalEnv)\n",
        "pops <- get(\"pops\", envir = .GlobalEnv)\n",
        "verbose <- get(\"verbose\", envir = .GlobalEnv)\n",
        "\n",
        "# Print the parameters to verify they are set correctly\n",
        "print(paste(\"Input prefix: \", inpref))\n",
        "print(paste(\"Output prefix: \", outpref))\n",
        "print(paste(\"Individuals: \", if (is.null(inds)) \"None\" else toString(inds)))\n",
        "print(paste(\"Populations: \", if (is.null(pops)) \"None\" else toString(pops)))\n",
        "print(paste(\"Verbose: \", verbose))\n",
        "\n",
        "# Run the conversion\n",
        "packedancestrymap_to_plink(\n",
        "  inpref = inpref,\n",
        "  outpref = outpref,\n",
        "  inds = inds,\n",
        "  pops = pops,\n",
        "  verbose = verbose\n",
        ")\n",
        "\n",
        "# Indicate completion\n",
        "print(\"Conversion complete. PLINK files are saved with the specified prefix.\")\n",
        "''')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiyOZ3U8hjid"
      },
      "source": [
        "### **Utility 2: PLINK to 23andMe Conversion (PLINK)**\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **plink_file**: Prefix of the PLINK input files without the extension.\n",
        "- **individual_id**: ID of the individual to be converted to 23andMe format.\n",
        "\n",
        "Ensure that the PLINK input files (.bed, .bim, .fam) are in the specified directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ybK5Kl8FhVik"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# Check if PLINK is already downloaded\n",
        "if not os.path.isfile('plink'):\n",
        "    # Download PLINK\n",
        "    !wget --no-check-certificate https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n",
        "    !unzip plink_linux_x86_64_20231211.zip\n",
        "    !chmod +x plink\n",
        "else:\n",
        "    print(\"PLINK is already downloaded. Skipping download step.\")\n",
        "\n",
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the PLINK input files without the extension\n",
        "plink_file = \"/content/Test5\"  # @param {type:\"string\"}\n",
        "\n",
        "# ID of the individual to be converted to 23andMe format\n",
        "individual_id = \"I3758.AG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Read the .fam file to get family and individual IDs\n",
        "fam_file = f\"{plink_file}.fam\"\n",
        "fam_df = pd.read_csv(fam_file, delim_whitespace=True, header=None)\n",
        "\n",
        "# Check if the individual ID exists in the .fam file\n",
        "if individual_id not in fam_df[1].values:\n",
        "    raise ValueError(f\"Individual ID {individual_id} not found in {fam_file}.\")\n",
        "\n",
        "# Create filter.txt for the specified individual\n",
        "filter_txt_content = fam_df[fam_df[1] == individual_id][[0, 1]].to_string(header=False, index=False)\n",
        "with open(\"filter.txt\", \"w\") as file:\n",
        "    file.write(filter_txt_content)\n",
        "\n",
        "# Run PLINK command to convert to 23andMe format\n",
        "plink_command = f\"./plink --bfile {plink_file} --keep filter.txt --snps-only --recode 23 --out {individual_id}\"\n",
        "subprocess.run(plink_command, shell=True)\n",
        "\n",
        "# Clean up\n",
        "os.remove(\"filter.txt\")\n",
        "\n",
        "# Print the PLINK log file\n",
        "log_file = f\"{individual_id}.log\"\n",
        "if os.path.isfile(log_file):\n",
        "    with open(log_file, 'r') as file:\n",
        "        print(\"PLINK Log File:\")\n",
        "        print(file.read())\n",
        "\n",
        "# Determine the correct 23andMe format file\n",
        "possible_files = [f for f in os.listdir() if f.startswith(individual_id) and f.endswith('.txt')]\n",
        "if possible_files:\n",
        "    final_txt_file = possible_files[0]\n",
        "    print(f\"\\nFirst 15 lines of the 23andMe format file ({final_txt_file}):\")\n",
        "    with open(final_txt_file, 'r') as file:\n",
        "        for _ in range(15):\n",
        "            print(file.readline().strip())\n",
        "else:\n",
        "    print(f\"23andMe format file for {individual_id} not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBia3xShh4en"
      },
      "source": [
        "### **Utility 3: PCA or MDS Plot Creation (PLINK)**\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **plink_file**: Prefix of the PLINK input files without the extension.\n",
        "- **method**: Choose between 'pca' and 'mds' for the analysis.\n",
        "- **count**: Number of dimensions to extract (for MDS) or principal components to extract (for PCA).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yT_hez0ah5wh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Check if PLINK is already downloaded\n",
        "if not os.path.isfile('plink'):\n",
        "    # Download PLINK\n",
        "    !wget --no-check-certificate https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20231211.zip\n",
        "    !unzip plink_linux_x86_64_20231211.zip\n",
        "    !chmod +x plink\n",
        "else:\n",
        "    print(\"PLINK is already downloaded. Skipping download step.\")\n",
        "\n",
        "# Define input parameters using Colab's form fields\n",
        "\n",
        "# Prefix of the PLINK input files without the extension\n",
        "plink_file = \"/content/Test5\"  # @param {type:\"string\"}\n",
        "\n",
        "# Choose between 'pca' and 'mds' for the analysis\n",
        "method = \"pca\"  # @param [\"pca\", \"mds\"]\n",
        "\n",
        "# Number of dimensions to extract (for MDS) or principal components to extract (for PCA)\n",
        "count = 25  # @param {type:\"number\"}\n",
        "\n",
        "# Figure size for the plot\n",
        "figsize_width = 20  # @param {type:\"slider\", min:5, max:50, step:1}\n",
        "figsize_height = 20  # @param {type:\"slider\", min:5, max:50, step:1}\n",
        "\n",
        "# Run PLINK command for PCA or MDS analysis\n",
        "if method == \"pca\":\n",
        "    plink_command = f\"./plink --bfile {plink_file} --pca {count} header tabs --out {plink_file}\"\n",
        "    subprocess.run(plink_command, shell=True)\n",
        "    eigenvec_file = f\"{plink_file}.eigenvec\"\n",
        "    eigenval_file = f\"{plink_file}.eigenval\"\n",
        "\n",
        "    # Read the eigenvec file\n",
        "    eigenvec_df = pd.read_csv(eigenvec_file, delim_whitespace=True)\n",
        "\n",
        "    # Plot PCA\n",
        "    plt.figure(figsize=(figsize_width, figsize_height), dpi=300)\n",
        "    sns.scatterplot(x=eigenvec_df.iloc[:, 2], y=eigenvec_df.iloc[:, 3], hue=eigenvec_df.iloc[:, 1], palette='deep', legend=False)\n",
        "\n",
        "    # Add sample labels\n",
        "    for i in range(len(eigenvec_df)):\n",
        "        plt.text(eigenvec_df.iloc[i, 2], eigenvec_df.iloc[i, 3], eigenvec_df.iloc[i, 1],\n",
        "                 fontsize=9, weight='bold', ha='right' if eigenvec_df.iloc[i, 2] > 0 else 'left',\n",
        "                 va='bottom' if eigenvec_df.iloc[i, 3] > 0 else 'top')\n",
        "\n",
        "    plt.title('PCA Plot', fontsize=16)\n",
        "    plt.xlabel('PC1', fontsize=14)\n",
        "    plt.ylabel('PC2', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the PCA data table of eigenvectors\n",
        "    print(\"Table of Eigenvectors:\")\n",
        "    display(eigenvec_df)\n",
        "\n",
        "elif method == \"mds\":\n",
        "    plink_command = f\"./plink --bfile {plink_file} --cluster --mds-plot {count} eigvals --out {plink_file}\"\n",
        "    subprocess.run(plink_command, shell=True)\n",
        "    mds_file = f\"{plink_file}.mds\"\n",
        "\n",
        "    # Read the mds file\n",
        "    mds_df = pd.read_csv(mds_file, delim_whitespace=True)\n",
        "\n",
        "    # Plot MDS\n",
        "    plt.figure(figsize=(figsize_width, figsize_height), dpi=300)\n",
        "    sns.scatterplot(x=mds_df.iloc[:, 3], y=mds_df.iloc[:, 4], hue=mds_df.iloc[:, 1], palette='deep', legend=False)\n",
        "\n",
        "    # Add sample labels\n",
        "    for i in range(len(mds_df)):\n",
        "        plt.text(mds_df.iloc[i, 3], mds_df.iloc[i, 4], mds_df.iloc[i, 1],\n",
        "                 fontsize=9, weight='bold', ha='right' if mds_df.iloc[i, 3] > 0 else 'left',\n",
        "                 va='bottom' if mds_df.iloc[i, 4] > 0 else 'top')\n",
        "\n",
        "    plt.title('MDS Plot', fontsize=16)\n",
        "    plt.xlabel('Dimension 1', fontsize=14)\n",
        "    plt.ylabel('Dimension 2', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the MDS data table\n",
        "    print(\"MDS Data Table:\")\n",
        "    display(mds_df)\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Invalid method selected. Choose either 'pca' or 'mds'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woa3SQ8Zv5Zw"
      },
      "source": [
        "## **Utility 4: Compute Fst (AT2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MQTNDvT8ugF4"
      },
      "outputs": [],
      "source": [
        "#@markdown **Input Parameters for Fst Computation**\n",
        "\n",
        "# Dataset prefix\n",
        "prefix = \"/content/Florio_mergedHO\"  # @param {type:\"string\"}\n",
        "\n",
        "# Population 1 (comma-separated population labels or file path)\n",
        "pop1_input = \"Florio\"  # @param {type:\"string\"}\n",
        "\n",
        "# Population 2 (comma-separated population labels or file path)\n",
        "pop2_input = \"Estonian.DG,Finnish.DG,French.DG,GBR.DG,IBS.DG,Icelandic.DG,TSI.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Use bootstrapping? (If FALSE, block-jackknife resampling will be used)\n",
        "boot = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# Adjust pseudohaploid (set to False if you have pseudohaploid samples)\n",
        "adjust_pseudohaploid = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# Function to parse population lists\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        # Split by commas and strip whitespace/quotes\n",
        "        return [pop.strip().strip(\"'\") for pop in poplist.split(',')]\n",
        "    return poplist\n",
        "\n",
        "# Parse the population lists\n",
        "pop1 = parse_poplist(pop1_input)\n",
        "pop2 = parse_poplist(pop2_input)\n",
        "\n",
        "# Import rpy2 for interfacing with R\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "# Pass the parameters to the R environment\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['pop1'] = robjects.StrVector(pop1)\n",
        "robjects.globalenv['pop2'] = robjects.StrVector(pop2)\n",
        "robjects.globalenv['boot'] = boot\n",
        "robjects.globalenv['adjust_pseudohaploid'] = adjust_pseudohaploid\n",
        "\n",
        "print(\"Input parameters set:\")\n",
        "print(f\"Dataset prefix: {prefix}\")\n",
        "print(f\"Population 1: {pop1}\")\n",
        "print(f\"Population 2: {pop2}\")\n",
        "print(f\"Bootstrapping: {boot}\")\n",
        "print(f\"Adjust pseudohaploid: {adjust_pseudohaploid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5cIMK4qMwenV"
      },
      "outputs": [],
      "source": [
        "#@markdown **Run Fst Computation**\n",
        "\n",
        "%%R\n",
        "# Load necessary libraries\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "\n",
        "# Retrieve parameters from Python\n",
        "prefix <- get(\"prefix\", envir = .GlobalEnv)\n",
        "pop1 <- get(\"pop1\", envir = .GlobalEnv)\n",
        "pop2 <- get(\"pop2\", envir = .GlobalEnv)\n",
        "boot <- get(\"boot\", envir = .GlobalEnv)\n",
        "adjust_pseudohaploid <- get(\"adjust_pseudohaploid\", envir = .GlobalEnv)\n",
        "\n",
        "# Print parameters for verification\n",
        "cat(\"Prefix path:\", prefix, \"\\n\")\n",
        "cat(\"Population 1:\", toString(pop1), \"\\n\")\n",
        "cat(\"Population 2:\", toString(pop2), \"\\n\")\n",
        "cat(\"Bootstrapping:\", boot, \"\\n\")\n",
        "cat(\"Adjust pseudohaploid:\", adjust_pseudohaploid, \"\\n\")\n",
        "\n",
        "# Compute Fst directly from genotype files\n",
        "fst_results <- fst(\n",
        "  data = prefix,\n",
        "  pop1 = pop1,\n",
        "  pop2 = pop2,\n",
        "  boot = boot,\n",
        "  verbose = TRUE,\n",
        "  adjust_pseudohaploid = adjust_pseudohaploid\n",
        ")\n",
        "\n",
        "# Output Fst results\n",
        "print(\"Fst computation complete.\")\n",
        "print(fst_results, n = Inf)  # Ensures all rows are displayed\n",
        "\n",
        "# Save results to a CSV file for convenience\n",
        "write.csv(fst_results, \"fst_results.csv\", row.names = FALSE)\n",
        "\n",
        "cat(\"Fst results saved to fst_results.csv.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEWag33Z2qms"
      },
      "source": [
        "### **Utility 5: Admixture Graphs (AT2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PSaBVczG2xTU"
      },
      "outputs": [],
      "source": [
        "#@markdown **Admixture Graph Input Parameters**\n",
        "\n",
        "# Dataset prefix for f-statistics\n",
        "prefix = \"/content/aadr_v62.0_HO_public\"  # @param {type:\"string\"}\n",
        "\n",
        "# Populations for admixture graph (comma-separated or user input)\n",
        "populations_input = \"Mbuti.DG,Israel_Natufian.AG,Israel_PPNB.AG,Russia_MA1_UP.SG,Turkey_Central_Boncuklu_PPN.AG,Turkey_Central_Pinarbasi_Epipaleolithic.AG,Morocco_Iberomaurusian.AG,Serbia_IronGates_Mesolithic.AG,Brazil_MG_C_LapaDoSanto_EH_HG_9600BP.AG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Number of admixture edges for find_graphs\n",
        "numadmix = 2  # @param {type:\"integer\"}\n",
        "\n",
        "# Output population for graph root\n",
        "outpop = \"Mbuti.DG\"  # @param {type:\"string\"}\n",
        "\n",
        "# Stop generation for find_graphs\n",
        "stop_gen = 25  # @param {type:\"integer\"}\n",
        "\n",
        "# Function to parse the population list\n",
        "def parse_poplist(poplist):\n",
        "    if isinstance(poplist, str):\n",
        "        return [pop.strip() for pop in poplist.split(\",\")]\n",
        "    return poplist\n",
        "\n",
        "# Parse user-specified populations\n",
        "populations = parse_poplist(populations_input)\n",
        "\n",
        "# Pass parameters to R environment\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "robjects.globalenv['prefix'] = prefix\n",
        "robjects.globalenv['populations'] = robjects.StrVector(populations)\n",
        "robjects.globalenv['numadmix'] = numadmix\n",
        "robjects.globalenv['outpop'] = outpop\n",
        "robjects.globalenv['stop_gen'] = stop_gen\n",
        "\n",
        "print(\"Input parameters set:\")\n",
        "print(f\"Prefix: {prefix}\")\n",
        "print(f\"Populations: {populations}\")\n",
        "print(f\"Number of admixture edges: {numadmix}\")\n",
        "print(f\"Outgroup population: {outpop}\")\n",
        "print(f\"Stop generation: {stop_gen}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WfF7qRF_63Ki"
      },
      "outputs": [],
      "source": [
        "#@markdown **Run Admixture Graph Analysis**\n",
        "\n",
        "%%R\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "library(plotly)\n",
        "\n",
        "# Retrieve parameters\n",
        "prefix <- get(\"prefix\", envir = globalenv())\n",
        "populations <- get(\"populations\", envir = globalenv())\n",
        "numadmix <- get(\"numadmix\", envir = globalenv())\n",
        "outpop <- get(\"outpop\", envir = globalenv())\n",
        "stop_gen <- get(\"stop_gen\", envir = globalenv())\n",
        "\n",
        "# Print parameters for verification\n",
        "cat(\"Prefix path:\", prefix, \"\\n\")\n",
        "cat(\"Populations:\", toString(populations), \"\\n\")\n",
        "cat(\"Number of admixture edges:\", numadmix, \"\\n\")\n",
        "cat(\"Outgroup population:\", outpop, \"\\n\")\n",
        "cat(\"Stop generation:\", stop_gen, \"\\n\")\n",
        "\n",
        "# Compute f2 blocks from the dataset\n",
        "cat(\"Computing f2 blocks...\\n\")\n",
        "f2_blocks <- f2_from_geno(prefix, pops = populations)\n",
        "\n",
        "# Automated graph exploration\n",
        "cat(\"Finding optimal graphs...\\n\")\n",
        "opt_results <- find_graphs(f2_blocks, numadmix = numadmix, outpop = outpop, stop_gen = stop_gen)\n",
        "\n",
        "# Extract the best graph\n",
        "winner <- opt_results %>% slice_min(score, with_ties = FALSE)\n",
        "\n",
        "# Display best graph score\n",
        "best_score <- winner$score[[1]]\n",
        "cat(\"Best graph score:\", best_score, \"\\n\")\n",
        "\n",
        "# Plot the best graph interactively\n",
        "cat(\"Visualizing the best graph...\\n\")\n",
        "best_graph <- winner$edges[[1]]\n",
        "\n",
        "# Use plotly to create and display an interactive graph\n",
        "interactive_plot <- plotly_graph(best_graph, fix = TRUE)\n",
        "\n",
        "# Save the graph edges and scores\n",
        "write.csv(best_graph, \"best_graph_edges.csv\", row.names = FALSE)\n",
        "cat(\"Best graph edges saved to best_graph_edges.csv.\\n\")\n",
        "\n",
        "# Output the plot for Jupyter Notebook\n",
        "interactive_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cl9SjKASFrqV"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to check and install required packages\n",
        "def install_and_import(package_name, package_alias=None):\n",
        "    try:\n",
        "        __import__(package_alias or package_name)\n",
        "    except ImportError:\n",
        "        print(f\"Package '{package_name}' not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "\n",
        "# Ensure required packages are installed\n",
        "install_and_import(\"python-igraph\", \"igraph\")\n",
        "install_and_import(\"matplotlib\")\n",
        "\n",
        "# Import igraph after ensuring it is installed\n",
        "from igraph import Graph, plot\n",
        "\n",
        "# Define custom parameters as form fields\n",
        "# Path to the graph file (CSV)\n",
        "graph_file = \"best_graph_edges.csv\"  # @param {type:\"string\"}\n",
        "\n",
        "# Edge width for connections\n",
        "edge_width = 2  # @param {type:\"slider\", min:0.5, max:10, step:0.1}\n",
        "\n",
        "# Font size for node labels\n",
        "font_size = 8  # @param {type:\"slider\", min:8, max:40, step:1}\n",
        "\n",
        "# Layout type (options: \"tree\" or \"kk\")\n",
        "layout_type = \"tree\"  # @param [\"tree\", \"kk\"]\n",
        "\n",
        "# Round percentages to this number of decimal places\n",
        "decimal_places = 1  # @param {type:\"slider\", min:0, max:3, step:1}\n",
        "\n",
        "# Plot dimensions\n",
        "plot_width = 20  # @param {type:\"slider\", min:10, max:100, step:1}\n",
        "plot_height = 12  # @param {type:\"slider\", min:10, max:100, step:1}\n",
        "\n",
        "# Background color\n",
        "background_color = \"white\"  # @param [\"white\", \"lightgray\", \"black\"]\n",
        "\n",
        "# Edge color\n",
        "edge_color = \"darkgray\"  # @param [\"darkgray\", \"black\", \"blue\", \"red\"]\n",
        "\n",
        "# Text color\n",
        "text_color = \"black\"  # @param [\"black\", \"white\", \"blue\", \"red\"]\n",
        "\n",
        "# Function to plot the admixture graph\n",
        "def plot_admixture_graph(graph_file, edge_width, font_size, layout_type, decimal_places, plot_width, plot_height, background_color, edge_color, text_color):\n",
        "    if not os.path.isfile(graph_file):\n",
        "        print(f\"Error: File '{graph_file}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Load edges from CSV\n",
        "    edges_df = pd.read_csv(graph_file)\n",
        "\n",
        "    # Create igraph object\n",
        "    g = Graph(directed=True)\n",
        "    g.add_vertices(list(set(edges_df[\"from\"].tolist() + edges_df[\"to\"].tolist())))\n",
        "    g.add_edges(zip(edges_df[\"from\"], edges_df[\"to\"]))\n",
        "\n",
        "    # Set layout\n",
        "    if layout_type == \"tree\":\n",
        "        layout = g.layout(\"rt\")\n",
        "    else:\n",
        "        layout = g.layout(\"kk\")\n",
        "\n",
        "    # Prepare vertex labels with rounded contributions\n",
        "    vertex_labels = []\n",
        "    for vertex in g.vs:\n",
        "        if vertex[\"name\"] in edges_df[\"to\"].values:\n",
        "            contribution = edges_df[edges_df[\"to\"] == vertex[\"name\"]][[\"from\", \"weight\"]]\n",
        "            contribution[\"weight\"] = contribution[\"weight\"].apply(lambda x: round(x * 100, decimal_places))  # Round\n",
        "            label = f\"{vertex['name']} ({', '.join(contribution['from'] + ': ' + contribution['weight'].astype(str) + '%')})\"\n",
        "            vertex_labels.append(label)\n",
        "        else:\n",
        "            vertex_labels.append(vertex[\"name\"])\n",
        "\n",
        "    # Dynamically calculate figure size based on layout\n",
        "    layout_coords = layout.coords  # Extract the coordinates\n",
        "    x_coords = [coord[0] for coord in layout_coords]\n",
        "    y_coords = [coord[1] for coord in layout_coords]\n",
        "    dynamic_width = max(x_coords) - min(x_coords)\n",
        "    dynamic_height = max(y_coords) - min(y_coords)\n",
        "    fig_width = max(dynamic_width / 2, plot_width)  # Scale width appropriately\n",
        "    fig_height = max(dynamic_height / 2, plot_height)  # Scale height appropriately\n",
        "\n",
        "    # Plot the graph\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "    ax.set_facecolor(background_color)  # Set background color\n",
        "    plot(\n",
        "        g,\n",
        "        layout=layout,\n",
        "        target=ax,\n",
        "        vertex_size=0,  # No default circles\n",
        "        vertex_label=vertex_labels,\n",
        "        vertex_label_size=font_size,\n",
        "        vertex_label_dist=0.5,  # Increase label distance from nodes\n",
        "        vertex_label_color=text_color,  # Set text color\n",
        "        vertex_label_fontweight=\"bold\",  # Bold text\n",
        "        edge_width=edge_width,\n",
        "        edge_color=edge_color,\n",
        "        bbox=None,  # Autoscale the graph\n",
        "        margin=max(dynamic_height / 10, 10),  # Dynamic margin\n",
        "    )\n",
        "    plt.title(\"Admixture Graph with Contributions\", fontsize=font_size + 4, fontweight=\"bold\", color=text_color)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with user-defined parameters\n",
        "plot_admixture_graph(\n",
        "    graph_file,\n",
        "    edge_width,\n",
        "    font_size,\n",
        "    layout_type,\n",
        "    decimal_places,\n",
        "    plot_width,\n",
        "    plot_height,\n",
        "    background_color,\n",
        "    edge_color,\n",
        "    text_color\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utility 6: AT2 qpAdm Rotation**"
      ],
      "metadata": {
        "id": "KSqthd0YBwNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **qpAdm Rotation Parameters (ADMIXTOOLS2)**\n",
        "This guide explains each parameter used in `qpAdm Rotation` and `extract_f2`, along with their **default values** and **descriptions**.\n",
        "\n",
        "---\n",
        "\n",
        "### **üìÇ Dataset & Paths**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `dataset_prefix` | `/content/dataset` | Path to the dataset prefix. Should match `.ind`, `.snp`, and `.geno` files. |\n",
        "| `my_f2_dir` | `/content/f2` | Directory where computed f2 statistics will be stored. If it exists, it will be cleared before new calculations. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üéØ Target & Population Inputs**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `target_pop` | `\"Example.DG\"` | The **target population** for qpAdm rotation, which remains fixed in all models. |\n",
        "| `leftright_pops` | `\"Example.DG,...\"` | Comma-separated list of **source populations**. |\n",
        "| `rightfix_pops` | `\"Mbuti.DG,...\"` | Comma-separated list of **fixed right (outgroup) populations**. |\n",
        "\n",
        "---\n",
        "\n",
        "### **‚öôÔ∏è Extract f2 Options (`extract_f2`)**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `adjust_pseudohaploid` | `True` | Ensures pseudohaploid samples contribute correctly to f2 statistics. Equivalent to `inbreed: NO` in ADMIXTOOLS 1. |\n",
        "| `qpfstats` | `False` | Computes **smoothed f2-statistics** to retain more SNPs in missing data scenarios. |\n",
        "| `blgsize` | `0.05` | SNP block size in **Morgans** (5 centimorgans). If set to `100` or higher, it is interpreted as **base pairs** instead. |\n",
        "| `maxmiss` | `0.2` | Discards SNPs missing in more than **20%** of populations. |\n",
        "| `minmaf` | `0` | Removes SNPs with a **minor allele frequency** (MAF) below this threshold. |\n",
        "\n",
        "---\n",
        "\n",
        "### **‚öôÔ∏è f2_from_precomp Options**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `afprod` | `True` | Computes **allele frequency products** for population pairs. Helps with admixture models but increases memory usage. |\n",
        "\n",
        "---\n",
        "\n",
        "### **‚öôÔ∏è qpAdm Rotation Options**\n",
        "| **Parameter** | **Default** | **Description** |\n",
        "|--------------|------------|----------------|\n",
        "| `full_results` | `True` | If `True`, saves **detailed output** from qpAdm, including **fitted f4-statistics** and population drop tests. |\n",
        "\n",
        "---\n",
        "\n",
        "### **üìå Notes**\n",
        "- **Required Parameters**: `dataset_prefix`, `target_pop`, `leftright_pops`, `rightfix_pops`.\n",
        "- **Filtering SNPs**: `maxmiss`, `minmaf`, `adjust_pseudohaploid` ensure only high-quality SNPs are used.\n",
        "- **Performance Optimization**: `qpfstats` can help with missing data but **introduces smoothing**.\n",
        "- **Memory Usage**: `afprod`, `qpfstats`, and `blgsize` affect speed and RAM consumption."
      ],
      "metadata": {
        "id": "QMUwdvSYY5Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Set Parameters for qpAdm Rotation (User-Defined Inputs)**\n",
        "import os\n",
        "import rpy2.robjects as robjects\n",
        "\n",
        "#@markdown **üìÇ Dataset & Paths**\n",
        "dataset_prefix = \"/content/Florio_mergedHO\"  #@param {type:\"string\"}\n",
        "my_f2_dir = \"/content/f2\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **üéØ Target Population (Fixed in all models)**\n",
        "target_pop = \"Example.DG\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **üß© Left Populations (Comma-separated)**\n",
        "leftright_pops = \"Luxembourg_Mesolithic.DG,Turkey_Marmara_Barcin_N.AG,Latvia_LN_CordedWare.AG\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **üìå Fixed Right Populations (Comma-separated)**\n",
        "rightfix_pops = \"Mbuti.DG,Russia_MA1_UP.SG,Switzerland_Bichon_Epipaleolithic.SG,Israel_Natufian.AG,Russia_Sidelkino_HG.SG,Georgia_Kotias_Mesolithic.SG,Turkey_Central_Pinarbasi_Epipaleolithic.AG,Russia_UstIshim_IUP.DG,Russia_AfontovaGora3_UP.AG,Tajikistan_Mesolithic.AG,Iran_GanjDareh_N.AG\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **‚öôÔ∏è Extract f2 Options**\n",
        "adjust_pseudohaploid = True  #@param {type:\"boolean\"}\n",
        "qpfstats = True  #@param {type:\"boolean\"}\n",
        "blgsize = 0.05  #@param {type:\"number\"}\n",
        "maxmiss = 0.2  #@param {type:\"number\"}\n",
        "minmaf = 0  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown **‚öôÔ∏è f2_from_precomp Options**\n",
        "afprod = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **‚öôÔ∏è qpAdm Rotation Options**\n",
        "full_results = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# Ensure f2 directory exists and clear it if necessary\n",
        "if os.path.exists(my_f2_dir) and os.path.isdir(my_f2_dir):\n",
        "    print(\"‚ö†Ô∏è Clearing existing f2 directory...\")\n",
        "    for root, dirs, files in os.walk(my_f2_dir, topdown=False):\n",
        "        for file in files:\n",
        "            os.remove(os.path.join(root, file))\n",
        "        for dir in dirs:\n",
        "            os.rmdir(os.path.join(root, dir))\n",
        "    print(\"‚úÖ f2 directory reset!\")\n",
        "\n",
        "# Convert strings to lists\n",
        "leftright_pops = [pop.strip() for pop in leftright_pops.split(\",\") if pop.strip()]\n",
        "rightfix_pops = [pop.strip() for pop in rightfix_pops.split(\",\") if pop.strip()]\n",
        "\n",
        "# Store values in R\n",
        "robjects.globalenv[\"prefix\"] = dataset_prefix\n",
        "robjects.globalenv[\"my_f2_dir\"] = my_f2_dir\n",
        "robjects.globalenv[\"target\"] = target_pop\n",
        "robjects.globalenv[\"leftright_pops\"] = robjects.StrVector(leftright_pops)\n",
        "robjects.globalenv[\"rightfix_pops\"] = robjects.StrVector(rightfix_pops)\n",
        "robjects.globalenv[\"adjust_pseudohaploid\"] = adjust_pseudohaploid\n",
        "robjects.globalenv[\"qpfstats\"] = qpfstats\n",
        "robjects.globalenv[\"blgsize\"] = blgsize\n",
        "robjects.globalenv[\"maxmiss\"] = maxmiss\n",
        "robjects.globalenv[\"minmaf\"] = minmaf\n",
        "robjects.globalenv[\"afprod\"] = afprod\n",
        "robjects.globalenv[\"full_results\"] = full_results\n",
        "\n",
        "# Debugging: Print inputs\n",
        "print(f\"‚úÖ Target: {target_pop}\")\n",
        "print(f\"‚úÖ Leftright populations ({len(leftright_pops)}): {leftright_pops}\")\n",
        "print(f\"‚úÖ Rightfix populations ({len(rightfix_pops)}): {rightfix_pops}\")\n",
        "print(f\"‚úÖ adjust_pseudohaploid: {adjust_pseudohaploid}\")\n",
        "print(f\"‚úÖ qpfstats: {qpfstats}\")\n",
        "print(f\"‚úÖ blgsize: {blgsize}, maxmiss: {maxmiss}, minmaf: {minmaf}\")\n",
        "print(f\"‚úÖ afprod: {afprod}\")\n",
        "print(f\"‚úÖ full_results: {full_results}\")\n",
        "print(\"‚úÖ Parameters set. Ready to run qpAdm Rotation.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C9gcY46wCdtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Extract f2 Blocks, Load f2 Data & Run qpAdm Rotation in R**\n",
        "import rpy2.robjects as robjects\n",
        "import pandas as pd\n",
        "from rpy2.robjects import pandas2ri\n",
        "from IPython.display import display\n",
        "\n",
        "# Enable Pandas compatibility with R\n",
        "pandas2ri.activate()\n",
        "\n",
        "# Run f2 extraction, loading, and qpAdm rotation in R\n",
        "robjects.r('''\n",
        "library(admixtools)\n",
        "library(tidyverse)\n",
        "\n",
        "# Extract f2 blocks\n",
        "cat(\"üîÑ Extracting f2 blocks...\\n\")\n",
        "tryCatch({\n",
        "  extract_f2(\n",
        "    pref = prefix,\n",
        "    outdir = my_f2_dir,\n",
        "    pops = c(target, leftright_pops, rightfix_pops),\n",
        "    blgsize = blgsize,\n",
        "    maxmiss = maxmiss,\n",
        "    minmaf = minmaf,\n",
        "    afprod = TRUE,\n",
        "    overwrite = TRUE,\n",
        "    adjust_pseudohaploid = adjust_pseudohaploid,\n",
        "    qpfstats = qpfstats,\n",
        "    verbose = TRUE\n",
        "  )\n",
        "  cat(\"‚úÖ f2 blocks extracted successfully!\\n\")\n",
        "}, error = function(e) {\n",
        "  stop(\"‚ùå f2 block computation failed! Check dataset and paths.\\n\", e$message)\n",
        "})\n",
        "\n",
        "# Load f2 statistics\n",
        "cat(\"üîÑ Loading f2 blocks...\\n\")\n",
        "f2_blocks <- tryCatch({\n",
        "  f2_from_precomp(dir = my_f2_dir, pops = c(target, leftright_pops, rightfix_pops), afprod = afprod)\n",
        "}, error = function(e) {\n",
        "  stop(\"‚ùå Error loading f2 blocks:\", e$message)\n",
        "})\n",
        "\n",
        "cat(\"‚úÖ f2 blocks loaded successfully!\\n\")\n",
        "\n",
        "# Run qpAdm rotation\n",
        "print(\"üîÑ Running qpAdm Rotation with Fixed Target & Right Groups...\")\n",
        "cat(\"‚úÖ Target Population:\", target, \"\\n\")\n",
        "cat(\"‚úÖ Left Populations:\", paste(leftright_pops, collapse=\", \"), \"\\n\")\n",
        "cat(\"‚úÖ Rightfix Populations:\", paste(rightfix_pops, collapse=\", \"), \"\\n\")\n",
        "\n",
        "results_qpadm_rotate <- tryCatch({\n",
        "  qpadm_rotate(\n",
        "    f2_blocks,\n",
        "    leftright = leftright_pops,\n",
        "    target = target,\n",
        "    rightfix = rightfix_pops,\n",
        "    full_results = TRUE  # Ensuring full results including weights\n",
        "  )\n",
        "}, error = function(e) {\n",
        "  stop(\"‚ùå qpAdm Rotation failed. Check f2 blocks and population lists.\\n\", e$message)\n",
        "})\n",
        "\n",
        "# üîß Save raw output for debugging\n",
        "saveRDS(results_qpadm_rotate, \"/content/qpadm_rotation_raw.rds\")\n",
        "\n",
        "# Extract weights properly\n",
        "extract_weights_df <- function(weights_list) {\n",
        "  bind_rows(lapply(weights_list, function(tbl) {\n",
        "    if (!is.null(tbl) && nrow(tbl) > 0 && \"weight\" %in% names(tbl)) {\n",
        "      tbl %>% select(left, weight, se, z)\n",
        "    } else {\n",
        "      tibble(left = NA, weight = NA, se = NA, z = NA)\n",
        "    }\n",
        "  }))\n",
        "}\n",
        "\n",
        "weights_df <- extract_weights_df(results_qpadm_rotate$weights)\n",
        "\n",
        "# Convert nested lists to a DataFrame-friendly format\n",
        "convert_to_df <- function(results) {\n",
        "  results %>%\n",
        "    mutate(\n",
        "      left = map_chr(left, ~ paste(.x, collapse=\", \")),\n",
        "      right = map_chr(right, ~ paste(.x, collapse=\", \")),\n",
        "      chisq = map_dbl(rankdrop, ~ .x$chisq[1]),\n",
        "      p = map_dbl(rankdrop, ~ .x$p[1]),\n",
        "      weights = map(weights, ~ if (!is.null(.x) && \"weight\" %in% names(.x)) {\n",
        "        paste(.x$weight, collapse=\", \")\n",
        "      } else {\n",
        "        \"No Weights Extracted\"\n",
        "      }),\n",
        "      feasible = map_lgl(weights, ~ all(as.numeric(strsplit(.x, \", \")[[1]]) >= 0, na.rm = TRUE))\n",
        "    ) %>%\n",
        "    select(left, right, chisq, p, weights, feasible) %>%\n",
        "    mutate(across(everything(), as.character))  # Convert lists to character\n",
        "}\n",
        "\n",
        "# Convert and process results\n",
        "rotation_df <- convert_to_df(results_qpadm_rotate)\n",
        "\n",
        "# Filter feasible models (Nonnegative Weights)\n",
        "feasible_models <- rotation_df %>%\n",
        "  filter(feasible == \"TRUE\") %>%\n",
        "  arrange(desc(as.numeric(p)))  # Sort by highest p-value\n",
        "\n",
        "# Save the full results and feasible models separately\n",
        "write.csv(rotation_df, \"/content/qpadm_rotation_results.csv\", row.names = FALSE)\n",
        "write.csv(feasible_models, \"/content/qpadm_rotation_results_feasible.csv\", row.names = FALSE)\n",
        "\n",
        "cat(\"‚úÖ qpAdm Rotation complete! Results saved to /content/qpadm_rotation_results.csv\\n\")\n",
        "cat(\"‚úÖ Feasible models saved to /content/qpadm_rotation_results_feasible.csv\\n\")\n",
        "\n",
        "# Print summary of feasible models\n",
        "print(feasible_models)\n",
        "\n",
        "# Extract and print best feasible model weights\n",
        "if (nrow(feasible_models) > 0) {\n",
        "  best_model <- feasible_models %>% slice(1)\n",
        "  cat(\"\\nüîç **Admixture Weights of the Best Feasible Model:**\\n\", best_model$weights, \"\\n\")\n",
        "} else {\n",
        "  cat(\"\\n‚ùå No feasible models found!\\n\")\n",
        "}\n",
        "\n",
        "feasible_models\n",
        "''')\n",
        "\n",
        "# Load feasible models from CSV\n",
        "feasible_models_df = pd.read_csv(\"/content/qpadm_rotation_results_feasible.csv\")\n",
        "\n",
        "# Display results\n",
        "display(feasible_models_df)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9R39K8mSy5TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Run Shiny ADMIXTOOLS GUI via Ngrok**\n",
        "!pip install pyngrok\n",
        "\n",
        "import os\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "#@markdown **Enter your Ngrok authtoken:**\n",
        "ngrok_authtoken = \"paste_authtoken_here\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Port number from previous step (default: 7110):**\n",
        "port_number = 7110  #@param {type:\"integer\"}\n",
        "\n",
        "# Configure ngrok with user-provided token\n",
        "ngrok.set_auth_token(ngrok_authtoken)\n",
        "\n",
        "# Start Ngrok Tunnel on the specified port\n",
        "public_url = ngrok.connect(port_number)\n",
        "print(f\"üåê Public URL: {public_url}\")\n",
        "\n",
        "# Function to run the Shiny app\n",
        "def run_shiny_admixtools():\n",
        "    script = f\"\"\"\n",
        "    library(admixtools)\n",
        "\n",
        "    # Use the specified port\n",
        "    run_shiny <- function() {{\n",
        "      options(shiny.port = {port_number})\n",
        "      admixtools::run_shiny_admixtools()\n",
        "    }}\n",
        "\n",
        "    run_shiny()\n",
        "    \"\"\"\n",
        "\n",
        "    # Write the script to a file\n",
        "    with open(\"run_shiny_app.R\", \"w\") as file:\n",
        "        file.write(script)\n",
        "\n",
        "    # Run the script\n",
        "    os.system(\"Rscript run_shiny_app.R\")\n",
        "\n",
        "# Start the Shiny app in a separate thread\n",
        "shiny_thread = threading.Thread(target=run_shiny_admixtools)\n",
        "shiny_thread.start()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4wOX0YoMIKTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make an account at [ngrok](https://dashboard.ngrok.com/login), go to the Dashboard and find your authtoken. Paste it above and click on the first link, click on the blue button and inside Data Directory, type in the filepath you set for your my_f2_dir above and load it. From there you can explore the other sections, including qpAdm GUI which allows you to build models from the fstats you precomputed. You can even share that link with others on another device if you'd like them to make qpAdm or qpGraph models from your f2 directory.**"
      ],
      "metadata": {
        "id": "fD6RILzFWUIQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}